# (2da parte del proyecto)

# Analizador de Sentimiento Biling√ºe (EN/ES) con XLM-RoBERTa + Hugging Face Spaces

Este proyecto implementa un analizador de sentimiento para **rese√±as de pel√≠culas** en **ingl√©s y espa√±ol** usando **Transformers**.  
Se compara un baseline r√°pido (**DistilRoBERTa**) frente a un modelo **multiling√ºe** (**XLM-RoBERTa base**) y se despliega una **app web** con **Gradio** en **Hugging Face Spaces** con una salida amigable para usuarios.

---

### [Notebook](./Notebook.ipynb)
### [Aplicaci√≥n](https://huggingface.co/spaces/Ricardouchub/sentiment-es-en)
### [Modelo en el Hub](https://huggingface.co/Ricardouchub/xlmr-sentiment-es-en)

## Dataset

Se utiliza el dataset de **cr√≠ticas de Rotten Tomatoes** (rese√±as de cr√≠ticos profesionales), con m√°s de **1 mill√≥n** de rese√±as.

- **Fuente:** [Kaggle ‚Äì Rotten Tomatoes Movies and Critic Reviews](https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset)

---

## Herramientas

- **Modelado:** Hugging Face **Transformers**, **Datasets**
- **Entrenamiento:** PyTorch (fp16/bf16 seg√∫n GPU), `gradient_checkpointing`, `cosine` scheduler, `EarlyStopping`
- **Particionado:** `GroupShuffleSplit` por **pel√≠cula** (evita fuga entre t√≠tulos)
- **App & Deploy:** **Gradio** en **Hugging Face Spaces**
- **M√©tricas:** Accuracy, F1, Precision, Recall, **ROC-AUC**, Matriz de Confusi√≥n

---

## Procedimiento

### 1) Preparaci√≥n de datos
- Auto-detecci√≥n de columnas (texto/etiqueta/agrupador).
- Limpieza ligera y normalizaci√≥n de la etiqueta.
- **Split por grupos (pel√≠cula)** con `GroupShuffleSplit`.

### 2) Modelado
- **Baselines:** DistilRoBERTa (r√°pido, EN).
- **Modelo principal:** **XLM-RoBERTa base** (multiling√ºe EN/ES).
- Submuestreo para comparaciones reproducibles: **100k train / 10k test**.

### 3) Entrenamiento y evaluaci√≥n
- Entrenamiento con fp16/bf16 (seg√∫n hardware), `gradient_checkpointing`.
- Evaluaci√≥n con m√©tricas est√°ndar y **barrido de umbral** para optimizar F1(1).

### 4) Despliegue
- App **Gradio** (Blocks) con:
  - pesta√±a **Texto √∫nico** y **Lote** (una rese√±a por l√≠nea),
  - **ejemplos precargados**,
  - output **amigable** (p. ej., *‚ÄúPositiva üëç (97.1%)‚Äù*),
  - **umbral fijo** en producci√≥n (por defecto `0.48`, configurable).
- **API**: el Space expone endpoints autom√°ticos; consulta el bot√≥n **‚ÄúUse via API‚Äù** en la p√°gina del Space para ver la ruta exacta y payload.

---

## Resultados (100k train / 10k test)

| Modelo               | Accuracy | F1     | Precision | Recall | AUC   | Umbral |
|----------------------|:-------:|:------:|:---------:|:------:|:-----:|:------:|
| DistilRoBERTa        | 0.8484  | 0.8882 | 0.8426    | **0.9390** | **0.9282** | 0.6046 |
| **XLM-RoBERTa (base)** | **0.8519** | 0.8876 | **0.8646** | 0.9119 | 0.9260 | **0.4800** |

**Matriz de confusi√≥n (umbral √≥ptimo por F1 de cada modelo):**
- DistilRoBERTa (0.6046): `[[TN=2463, FP=1125], [FN=391, TP=6021]]`
- XLM-R (0.4800): `[[TN=2672, FP=916],  [FN=565, TP=5847]]`

**Lectura:** XLM-R logra **mayor precisi√≥n** (menos FP) y **ligera mejora en accuracy**, sacrificando algo de recall frente a DistilRoBERTa. Adem√°s, ofrece **biling√ºismo** (EN/ES), por lo que es el modelo elegido para la app.

---

## C√≥mo usar la App (Space)

1. Escribe una rese√±a en ingl√©s o espa√±ol y pulsa **Analizar**.  
2. Para varias rese√±as, usa la pesta√±a **Lote** (una por l√≠nea).  
3. El Space incluye un bot√≥n **‚ÄúUse via API‚Äù** con el **endpoint** y un **ejemplo de payload** para integrar en tus proyectos.

**Variables de entorno √∫tiles (Space Settings ‚Üí Variables & secrets):**
- `HF_REPO_ID` ‚Üí `Ricardouchub/xlmr-sentiment-es-en`
- `THRESHOLD` ‚Üí `0.48` (puedes re-ajustar seg√∫n validaci√≥n)
- `HF_TOKEN` ‚Üí solo si el repositorio del modelo es **privado**

---

## Conclusiones

XLM-RoBERTa base es el modelo de producci√≥n por su biling√ºismo y mejor Precisi√≥n/Accuracy a umbral ‚âà 0.48, manteniendo un recall alto.

El split por pel√≠cula evita fuga y hace la evaluaci√≥n honesta.

La app web es simple de usar y cuenta con API para integraci√≥n.

---

## Autor

**Ricardo Urdaneta** 
**[Linkedin](https://www.linkedin.com/in/ricardourdanetacastro/)**