import os, torch, gradio as gr
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pandas as pd  

# =========================
# Configuraci√≥n
# =========================
REPO_ID   = os.getenv("HF_REPO_ID", "Ricardouchub/xlmr-sentiment-es-en")
THRESHOLD = float(os.getenv("THRESHOLD", "0.48"))
MAX_LEN   = int(os.getenv("MAX_LEN", "224"))
DEVICE    = "cuda:0" if torch.cuda.is_available() else "cpu"
HF_TOKEN  = os.getenv("HF_TOKEN")  

# =========================
# Carga √∫nica del modelo
# =========================
tok = AutoTokenizer.from_pretrained(REPO_ID, use_fast=True, token=HF_TOKEN)
mdl = AutoModelForSequenceClassification.from_pretrained(REPO_ID, token=HF_TOKEN).to(DEVICE).eval()

labels = {0: "Negativa", 1: "Positiva"}
icons  = {0: "üëé", 1: "üëç"}

# =========================
# Funciones de inferencia
# =========================
@torch.inference_mode()
def predict_single(text: str):
    enc = tok([text], truncation=True, max_length=MAX_LEN, padding=True, return_tensors="pt").to(DEVICE)
    probs = torch.softmax(mdl(**enc).logits, dim=-1)[:, 1]  # prob. clase positiva
    score = float(probs[0].item())
    label = 1 if score >= THRESHOLD else 0
    lbl = labels[label]
    conf_pct = round(score * 100, 1)
    emoji = icons[label]
    return f"**El sentimiento es {lbl} {emoji} con una confianza de {conf_pct}%.**"

@torch.inference_mode()
def predict_batch(raw_text: str):
    texts = [t.strip() for t in raw_text.splitlines() if t.strip()]
    if not texts:
        return pd.DataFrame(columns=["Texto", "Sentimiento", "Confianza (%)"])
    enc = tok(texts, truncation=True, max_length=MAX_LEN, padding=True, return_tensors="pt").to(DEVICE)
    probs = torch.softmax(mdl(**enc).logits, dim=-1)[:, 1]
    rows = []
    for t, p in zip(texts, probs.tolist()):
        label = 1 if p >= THRESHOLD else 0
        lbl = labels[label]
        emoji = icons[label]
        rows.append({"Texto": t, "Sentimiento": f"{lbl} {emoji}", "Confianza (%)": round(p * 100, 1)})
    return pd.DataFrame(rows)

# =========================
# Interfaz Gradio
# =========================
with gr.Blocks(title="Analizador de Sentimiento Biling√ºe de Rese√±a de Pel√≠culas (EN/ES)") as demo:
    # Encabezado y m√©tricas actualizadas (XLM-R 100k/10k)
    gr.Markdown(
        f"""
# Analizador de Sentimiento Biling√ºe de Rese√±a de Pel√≠culas (EN/ES)
Clasifica rese√±as en **ingl√©s o espa√±ol** como *Positivas* o *Negativas* usando **XLM-RoBERTa base** (modelo multiling√ºe EN/ES).

**Modelo:** `{REPO_ID}` ¬∑ **Dispositivo:** `{DEVICE}`  
**Resultados:** *Accuracy = **0.8519** ¬∑ F1 = **0.8876** ¬∑ Precision = **0.8646** ¬∑ Recall = **0.9119** ¬∑ AUC = **0.9260***  
**Umbral operativo:** **{THRESHOLD}**
"""
    )

    # Resumen del proyecto (dataset, split, entrenamiento, API)
    with gr.Tab("Texto √∫nico"):
        inp = gr.Textbox(
            label="Escribe una rese√±a en ingl√©s o espa√±ol",
            lines=4,
            placeholder="Excelente fotograf√≠a, pero la historia es floja‚Ä¶ / Great acting, but the plot felt predictable."
        )
        gr.Examples(
            examples=[
                ["This movie was fantastic, a true masterpiece of cinema."],
                ["La pel√≠cula fue una completa p√©rdida de tiempo, muy aburrida."],
                ["It wasn't bad, but it didn't meet my expectations."],
                ["Me gust√≥ la actuaci√≥n, aunque la trama era un poco predecible."]
            ],
            inputs=[inp],
            label="Prueba con ejemplos r√°pidos"
        )
        btn = gr.Button("Analizar", variant="primary")
        out = gr.Markdown(label="Resultado")
        btn.click(predict_single, inputs=inp, outputs=out)

    with gr.Tab("Lote (una por l√≠nea)"):
        batch_inp = gr.Textbox(
            label="Pega varias rese√±as (una por l√≠nea)",
            lines=8,
            placeholder="Escribe una rese√±a por l√≠nea‚Ä¶"
        )
        btn2 = gr.Button("Analizar Lote")
        out2 = gr.Dataframe(label="Resultados", wrap=True)
        btn2.click(predict_batch, inputs=batch_inp, outputs=out2)

    # Footer con autor y enlaces
    gr.Markdown("---")
    gr.Markdown("**Realizado por: Ricardo Urdaneta**")
    with gr.Row():
        gr.Button("LinkedIn", link="https://www.linkedin.com/in/ricardourdanetacastro", size="sm")
        gr.Button("GitHub",   link="https://github.com/Ricardouchub",                  size="sm")

if __name__ == "__main__":
    demo.launch()