{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007d9518",
   "metadata": {},
   "source": [
    "# Analizador de Sentimiento Biling√ºe en Rese√±as de Pel√≠culas (EN/ES) con XLM-R\n",
    "\n",
    "## Resumen\n",
    "Este trabajo es una **extensi√≥n y mejora** de *‚ÄúAn√°lisis de Rese√±as de Rotten Tomatoes con NLP‚Äù* (modelo cl√°sico de **Regresi√≥n Log√≠stica**, Acc‚âà81% sobre >1M rese√±as).  \n",
    "Aqu√≠ migramos a arquitecturas **Transformers**, comparamos **DistilRoBERTa** (baseline r√°pido) con **XLM-RoBERTa base (XLM-R)** para soporte **biling√ºe EN/ES**, y **desplegamos** el mejor sistema como una aplicaci√≥n accesible (Gradio en Hugging Face Spaces).\n",
    "\n",
    "Usamos un split **group-aware por pel√≠cula** y un escenario de comparaci√≥n **100k/10k** (train/test) para iteraci√≥n r√°pida. Adem√°s, ajustamos el **umbral de decisi√≥n** para equilibrar precisi√≥n/recobrado en uso real.\n",
    "\n",
    "**Resultados (100k/10k, umbral √≥ptimo por F1 de cada modelo):**\n",
    "- **DistilRoBERTa** ‚Üí Acc **0.8484** ¬∑ F1 **0.8882** ¬∑ Prec 0.8426 ¬∑ **Rec 0.9390** ¬∑ AUC **0.9282** ¬∑ *thr‚âà0.6046*  \n",
    "- **XLM-R (base)** ‚Üí **Acc 0.8519** ¬∑ F1 0.8876 ¬∑ **Prec 0.8646** ¬∑ Rec 0.9119 ¬∑ AUC 0.9260 ¬∑ *thr‚âà0.4800*  \n",
    "\n",
    "**Conclusi√≥n breve:** XLM-R ofrece **menor tasa de falsos positivos** (‚ÜëPrecisi√≥n) con exactitud ligeramente superior, manteniendo un recall alto y habilitando **biling√ºismo**; por ello es el modelo elegido para despliegue (umbral operativo ‚âà **0.48**).\n",
    "\n",
    "---\n",
    "\n",
    "## Metodolog√≠a\n",
    "1. **Datos**: rese√±as de cr√≠ticos de *Rotten Tomatoes* (Kaggle; >1M).  \n",
    "2. **Preprocesamiento**:\n",
    "   - Auto-detecci√≥n de columnas (texto/etiqueta/agrupador) y **limpieza m√≠nima** (HTML, espacios, contracciones).\n",
    "   - Normalizaci√≥n de etiqueta binaria (`Fresh`/`Rotten` ‚Üí {1,0}).\n",
    "3. **Partici√≥n**:\n",
    "   - **GroupShuffleSplit** por pel√≠cula (evita fuga de informaci√≥n por t√≠tulo).\n",
    "   - Submuestreo estratificado para escenarios **50k/10k** y **100k/10k**.\n",
    "4. **Modelado**:\n",
    "   - **DistilRoBERTa** (baseline r√°pido, EN).\n",
    "   - **XLM-R base** (modelo principal, **EN/ES**).\n",
    "   - Entrenamiento con `fp16/bf16` (seg√∫n GPU), `gradient_checkpointing`, `cosine` scheduler, `EarlyStopping`.\n",
    "5. **Evaluaci√≥n**:\n",
    "   - `Accuracy`, `F1`, `Precision`, `Recall`, `ROC-AUC`.\n",
    "   - Barrido de **umbral** y reporte de matriz de confusi√≥n.\n",
    "6. **Despliegue**:\n",
    "   - App **Gradio** en Hugging Face Spaces.\n",
    "   - **API** autoexpuesta con endpoints `/predict_single` y `/predict_batch`.\n",
    "\n",
    "---\n",
    "\n",
    "> **Modelo en despliegue:** XLM-R base (EN/ES), umbral operativo ‚âà **0.48**, consumido por la app Gradio y su API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4706609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del CSV: ['rotten_tomatoes_link', 'critic_name', 'top_critic', 'publisher_name', 'review_type', 'review_score', 'review_date', 'review_content']\n"
     ]
    }
   ],
   "source": [
    "# Lectura del CSV de cr√≠ticas de Rotten Tomatoes\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/rotten_tomatoes_critic_reviews.csv')\n",
    "\n",
    "# Inspecci√≥n r√°pida de columnas disponibles \n",
    "print(\"Columnas del CSV:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9435ab",
   "metadata": {},
   "source": [
    "## 2) Preparaci√≥n del Dataset (detecci√≥n de columnas, limpieza y normalizaci√≥n)\n",
    "\n",
    "En esta secci√≥n:\n",
    "- **Auto-detectamos** las columnas de texto, etiqueta y agrupador (pel√≠cula).\n",
    "- **Limpiamos** el texto (HTML, espacios, contracciones).\n",
    "- **Normalizamos** la etiqueta a binaria `sentimiento ‚àà {0,1}`.\n",
    "- Construimos un **DataFrame est√°ndar** con: `review_clean`, `sentimiento`, `group_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30604952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Columnas detectadas: {'text_col': 'review_content', 'label_col': 'review_type', 'group_col': 'rotten_tomatoes_link'}\n",
      "                                        review_clean  sentimiento  group_key\n",
      "0  A fantasy adventure that fuses Greek mythology...            1  m/0814255\n",
      "1  Uma Thurman as Medusa, the gorgon with a coiff...            1  m/0814255\n",
      "2  With a top-notch cast and dazzling special eff...            1  m/0814255\n",
      "\n",
      ">> Nulos por columna:\n",
      " review_clean    0\n",
      "sentimiento     0\n",
      "group_key       0\n",
      "dtype: int64\n",
      "\n",
      ">> Distribuci√≥n de la etiqueta (0/1):\n",
      "               count\n",
      "sentimiento        \n",
      "1            720210\n",
      "0            409807\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Configuraci√≥n\n",
    "# ============================\n",
    "from __future__ import annotations\n",
    "import re, html, warnings\n",
    "import pandas as pd\n",
    "from typing import Iterable, Optional, Tuple, Dict, Any\n",
    "\n",
    "TEXT_CANDIDATES  = [\"review_clean\",\"review\",\"review_text\",\"review_content\",\"content\",\"text\",\"critic_review\"]\n",
    "LABEL_CANDIDATES = [\"sentimiento\",\"fresh\",\"label\",\"freshness\",\"review_type\",\"target\",\"y\"]\n",
    "GROUP_CANDIDATES = [\"rotten_tomatoes_link\",\"movie_title\",\"title\",\"movie\",\"film\"]\n",
    "\n",
    "# Sin√≥nimos / formatos v√°lidos para etiquetas\n",
    "LABEL_MAP_TEXT_POS = {\n",
    "    \"fresh\",\"positivo\",\"positive\",\"pos\",\"freshness_fresh\",\"freshness fresh\"\n",
    "}\n",
    "LABEL_MAP_TEXT_NEG = {\n",
    "    \"rotten\",\"negativo\",\"negative\",\"neg\",\"freshness_rotten\",\"freshness rotten\"\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# Detecci√≥n de columnas\n",
    "# ============================\n",
    "def pick_first(cols: Iterable[str], candidates: Iterable[str]) -> Optional[str]:\n",
    "    \"\"\"Devuelve el primer nombre de 'candidates' que exista en 'cols'; None si no hay coincidencia.\"\"\"\n",
    "    cols_set = set(cols)\n",
    "    for c in candidates:\n",
    "        if c in cols_set:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def detect_columns(df: pd.DataFrame) -> Tuple[str, str, str]:\n",
    "    \"\"\"Detecta (text_col, label_col, group_col). Si group no existe, usa fallback.\"\"\"\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    text_col = pick_first(cols, TEXT_CANDIDATES)\n",
    "    if text_col is None:\n",
    "        raise ValueError(\n",
    "            \"No se encontr√≥ una columna de texto. Agrega una de: \"\n",
    "            + \", \".join([f\"'{c}'\" for c in TEXT_CANDIDATES])\n",
    "        )\n",
    "\n",
    "    label_col = pick_first(cols, LABEL_CANDIDATES)\n",
    "    if label_col is None:\n",
    "        raise ValueError(\n",
    "            \"No se encontr√≥ una columna de etiqueta. Agrega una de: \"\n",
    "            + \", \".join([f\"'{c}'\" for c in LABEL_CANDIDATES])\n",
    "        )\n",
    "\n",
    "    group_col = pick_first(cols, GROUP_CANDIDATES)\n",
    "    if group_col is None:\n",
    "        # fallback por t√≠tulo o √≠ndice\n",
    "        group_col = pick_first(cols, [\"movie_title\",\"title\"])\n",
    "        if group_col is None:\n",
    "            warnings.warn(\n",
    "                \"No hay columna de agrupaci√≥n (pel√≠cula). \"\n",
    "                \"Se crear√° '_group_fallback' agrupando por bloques de 10 √≠ndices (no ideal).\",\n",
    "                UserWarning\n",
    "            )\n",
    "            df[\"_group_fallback\"] = (df.index // 10)\n",
    "            group_col = \"_group_fallback\"\n",
    "\n",
    "    return text_col, label_col, group_col\n",
    "\n",
    "# ============================\n",
    "# Limpieza de texto\n",
    "# ============================\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "WS_RE  = re.compile(r\"\\s+\")\n",
    "CONTRACTION_RE = re.compile(r\"n['‚Äô]t\\b\", flags=re.IGNORECASE)  # don't/don‚Äôt ‚Üí do not\n",
    "\n",
    "def clean_text(t: Any) -> str:\n",
    "    \"\"\"Limpieza m√≠nima: HTML ‚Üí texto, contrae 'n't'‚Üí ' not', normaliza espacios.\"\"\"\n",
    "    if not isinstance(t, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(t)\n",
    "    t = TAG_RE.sub(\" \", t)\n",
    "    t = CONTRACTION_RE.sub(\" not\", t)\n",
    "    t = WS_RE.sub(\" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# ============================\n",
    "# Normalizaci√≥n de etiqueta\n",
    "# ============================\n",
    "def to_binary_label(v: Any) -> Optional[int]:\n",
    "    \"\"\"Convierte etiquetas heterog√©neas a {0,1}. Devuelve None si no se puede mapear.\"\"\"\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "\n",
    "    # Texto\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip().lower()\n",
    "        if s in LABEL_MAP_TEXT_POS or \"fresh\" in s:\n",
    "            return 1\n",
    "        if s in LABEL_MAP_TEXT_NEG or \"rotten\" in s:\n",
    "            return 0\n",
    "\n",
    "    # Num√©rico\n",
    "    try:\n",
    "        f = float(v)\n",
    "        if f in (0.0, 1.0):\n",
    "            return int(f)\n",
    "        if 0.0 <= f <= 1.0:\n",
    "            return int(round(f))        # e.g., probabilidad ya en [0,1]\n",
    "        if 1.0 <= f <= 5.0:\n",
    "            return int(f >= 3.0)        # rating 1‚Äì5 ‚Üí >=3 positivo\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "# ============================\n",
    "# Pipeline de preparaci√≥n\n",
    "# ============================\n",
    "def prepare_reviews_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estandariza el DataFrame para el pipeline:\n",
    "    - detecta columnas (texto, label, grupo)\n",
    "    - limpia texto ‚Üí 'review_clean'\n",
    "    - normaliza etiqueta ‚Üí 'sentimiento' (0/1)\n",
    "    - renombra grupo ‚Üí 'group_key'\n",
    "    - filtra nulos y devuelve solo columnas est√°ndar\n",
    "    \"\"\"\n",
    "    text_col, label_col, group_col = detect_columns(df)\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    # Limpieza de texto\n",
    "    out[\"review_clean\"] = out[text_col].map(clean_text)\n",
    "\n",
    "    # Normaliza etiqueta binaria\n",
    "    out[\"sentimiento\"] = out[label_col].apply(to_binary_label)\n",
    "\n",
    "    # Mantener trio est√°ndar\n",
    "    out = out[[\"review_clean\", \"sentimiento\", group_col]].dropna(subset=[\"review_clean\",\"sentimiento\"])\n",
    "    out = out.rename(columns={group_col: \"group_key\"})\n",
    "\n",
    "    return out, {\"text_col\": text_col, \"label_col\": label_col, \"group_col\": group_col}\n",
    "\n",
    "# ============================\n",
    "# 6) Ejecutar preparaci√≥n y diagn√≥stico\n",
    "# ============================\n",
    "prepared_df, col_info = prepare_reviews_dataframe(df)\n",
    "\n",
    "print(\">> Columnas detectadas:\", col_info)\n",
    "print(prepared_df[[\"review_clean\",\"sentimiento\",\"group_key\"]].head(3))\n",
    "print(\"\\n>> Nulos por columna:\\n\", prepared_df.isna().sum())\n",
    "print(\"\\n>> Distribuci√≥n de la etiqueta (0/1):\\n\", prepared_df[\"sentimiento\"].value_counts(dropna=False).to_frame(\"count\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7026b",
   "metadata": {},
   "source": [
    "## 2) Construcci√≥n del set de entrenamiento/prueba (salteando baselines)\n",
    "\n",
    "En esta secci√≥n preparamos los datos **directamente** para evaluar el modelo final (XLM-R), omitiendo los modelos intermedios y sus *tunings*.\n",
    "\n",
    "**Objetivos:**\n",
    "- Estandarizar columnas a: `text` (entrada), `label` (0/1), `group` (pel√≠cula).\n",
    "- Asegurar una **partici√≥n por grupos** (pel√≠cula) con `GroupShuffleSplit` 80/20 para evitar fuga de informaci√≥n.\n",
    "- Dejar `X_train`, `y_train`, `X_test`, `y_test` listos para inferencia/evaluaci√≥n del modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6628fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2.1) Imports y configuraci√≥n reproducible\n",
    "# ============================================\n",
    "import re, html, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE    = 0.20\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5b8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 2.2) Utilidades m√≠nimas (limpieza, binarizaci√≥n, detecci√≥n)\n",
    "# ==============================================================\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    \"\"\"Limpieza m√≠nima: HTML->texto, normaliza espacios, expande n't ‚Üí not.\"\"\"\n",
    "    if not isinstance(t, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(t)\n",
    "    t = re.sub(r\"<[^>]+>\", \" \", t)\n",
    "    t = re.sub(r\"n['‚Äô]t\\b\", \" not\", t)  # don't/don‚Äôt ‚Üí do not\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def pick_first(cols, cands):\n",
    "    \"\"\"Devuelve el primer nombre en cands que exista en cols, o None.\"\"\"\n",
    "    cols = set(cols)\n",
    "    for c in cands:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def binarize_label(v):\n",
    "    \"\"\"Normaliza etiqueta heterog√©nea a {0,1}. Devuelve None si no mapea.\"\"\"\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip().lower()\n",
    "        if \"fresh\" in s or s in {\"positive\",\"pos\",\"freshness fresh\",\"freshness_fresh\"}:\n",
    "            return 1\n",
    "        if \"rotten\" in s or s in {\"negative\",\"neg\",\"freshness rotten\",\"freshness_rotten\"}:\n",
    "            return 0\n",
    "    try:\n",
    "        f = float(v)\n",
    "        if f in (0, 1):\n",
    "            return int(f)\n",
    "        if 0 <= f <= 1:\n",
    "            return int(round(f))     # si ya vino como prob en [0,1]\n",
    "        if 1 <= f <= 5:\n",
    "            return int(f >= 3)       # rating 1‚Äì5 ‚Üí >=3 positivo\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06577a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Ejemplo de filas estandarizadas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label      group\n",
       "0  A fantasy adventure that fuses Greek mythology...      1  m/0814255\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...      1  m/0814255\n",
       "2  With a top-notch cast and dazzling special eff...      1  m/0814255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Distribuci√≥n global de la etiqueta:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "label        \n",
       "1      720210\n",
       "0      409807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# 2.3) Estandarizaci√≥n a (text, label, group) con fallback de agrupador\n",
    "# =====================================================================\n",
    "# Asumimos que ya tienes un DataFrame `df` con las columnas originales.\n",
    "\n",
    "# Si ya trabajaste la secci√≥n previa y tienes `prepared_df` con:\n",
    "#   [\"review_clean\",\"sentimiento\",\"group_key\"]\n",
    "# puedes descomentar estas 3 l√≠neas y saltarte la auto-detecci√≥n:\n",
    "#\n",
    "# df_trf = prepared_df.rename(columns={\n",
    "#     \"review_clean\": \"text\", \"sentimiento\": \"label\", \"group_key\": \"group\"\n",
    "# })[[\"text\",\"label\",\"group\"]].dropna()\n",
    "# display(df_trf.head())\n",
    "\n",
    "# Si NO tienes `prepared_df`, usamos auto-detecci√≥n r√°pida:\n",
    "text_col  = pick_first(df.columns, [\"review_clean\",\"review\",\"review_text\",\"review_content\",\"content\",\"text\",\"critic_review\"])\n",
    "label_col = pick_first(df.columns, [\"sentimiento\",\"fresh\",\"label\",\"freshness\",\"review_type\",\"target\",\"y\"])\n",
    "group_col = pick_first(df.columns, [\"rotten_tomatoes_link\",\"movie_title\",\"title\",\"movie\",\"film\"])\n",
    "\n",
    "if text_col is None or label_col is None:\n",
    "    raise ValueError(\"No encuentro columnas de texto/label. Revisa nombres en tu CSV/DF.\")\n",
    "\n",
    "if group_col is None:\n",
    "    # Agrupador m√≠nimo por √≠ndice para evitar fuga total (no ideal, pero mejor que nada)\n",
    "    df[\"_group_key\"] = (df.index // 10)\n",
    "    group_col = \"_group_key\"\n",
    "\n",
    "df_trf = pd.DataFrame({\n",
    "    \"text\":  df[text_col].map(clean_text),\n",
    "    \"label\": df[label_col].map(binarize_label),\n",
    "    \"group\": df[group_col]\n",
    "}).dropna()\n",
    "\n",
    "# Tipado final de la etiqueta\n",
    "df_trf[\"label\"] = df_trf[\"label\"].astype(int)\n",
    "\n",
    "print(\">> Ejemplo de filas estandarizadas:\")\n",
    "display(df_trf.head(3))\n",
    "\n",
    "print(\"\\n>> Distribuci√≥n global de la etiqueta:\")\n",
    "display(df_trf[\"label\"].value_counts(normalize=False).to_frame(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b09a954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Tama√±os ‚Üí train: 908,582 | test: 221,435\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2.4) Split 80/20 con GroupShuffleSplit (evita fuga por film)\n",
    "# ==========================================================\n",
    "X_all      = df_trf[\"text\"]\n",
    "y_all      = df_trf[\"label\"]\n",
    "groups_all = df_trf[\"group\"]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "tr_idx, te_idx = next(gss.split(X_all, y_all, groups_all))\n",
    "\n",
    "X_train, X_test = X_all.iloc[tr_idx].reset_index(drop=True), X_all.iloc[te_idx].reset_index(drop=True)\n",
    "y_train, y_test = y_all.iloc[tr_idx].reset_index(drop=True), y_all.iloc[te_idx].reset_index(drop=True)\n",
    "groups_train    = groups_all.iloc[tr_idx].reset_index(drop=True)\n",
    "groups_test     = groups_all.iloc[te_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\">> Tama√±os ‚Üí train: {len(X_train):,} | test: {len(X_test):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef578b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reporte de partici√≥n (group-aware):\n",
      "   - label_train_counts: {1: 578236, 0: 330346}\n",
      "   - label_test_counts: {1: 141974, 0: 79461}\n",
      "   - n_groups_train: 14169\n",
      "   - n_groups_test: 3543\n",
      "   - groups_overlap: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>578236</td>\n",
       "      <td>141974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330346</td>\n",
       "      <td>79461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train    test\n",
       "label                \n",
       "1      578236  141974\n",
       "0      330346   79461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2.5) Chequeos r√°pidos (sanity checks)\n",
    "# =========================================\n",
    "def quick_report(y_tr, y_te, g_tr, g_te):\n",
    "    rep = {}\n",
    "    rep[\"label_train_counts\"] = y_tr.value_counts().to_dict()\n",
    "    rep[\"label_test_counts\"]  = y_te.value_counts().to_dict()\n",
    "    rep[\"n_groups_train\"]     = g_tr.nunique()\n",
    "    rep[\"n_groups_test\"]      = g_te.nunique()\n",
    "    rep[\"groups_overlap\"]     = bool(set(g_tr.unique()) & set(g_te.unique()))\n",
    "    return rep\n",
    "\n",
    "report = quick_report(y_train, y_test, groups_train, groups_test)\n",
    "print(\">> Reporte de partici√≥n (group-aware):\")\n",
    "for k, v in report.items():\n",
    "    print(f\"   - {k}: {v}\")\n",
    "\n",
    "# Aseguramos NO overlap de grupos entre train y test:\n",
    "assert not report[\"groups_overlap\"], \"Hay solapamiento de grupos entre train y test (riesgo de fuga).\"\n",
    "\n",
    "# Vista r√°pida de clases:\n",
    "display(pd.DataFrame({\n",
    "    \"train\": y_train.value_counts(),\n",
    "    \"test\":  y_test.value_counts()\n",
    "}).fillna(0).astype(int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44ebc5",
   "metadata": {},
   "source": [
    "> **Checklist**\n",
    "> - [x] `df_trf` estandarizado con `text`, `label`, `group`.\n",
    "> - [x] Split 80/20 **por pel√≠cula** con `GroupShuffleSplit`.\n",
    "> - [x] Sin solapamiento de `group` entre train y test.\n",
    "> - [x] `X_train`, `y_train`, `X_test`, `y_test` listos para evaluaci√≥n del modelo final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587479d",
   "metadata": {},
   "source": [
    "## 3) Entrenamiento r√°pido del modelo final (salteando baselines y tunning)\n",
    "\n",
    "En esta secci√≥n entrenaremos un modelo de *Transformers* directamente sobre un **subset** (50k train / 10k test) para iterar r√°pido.  \n",
    "- Usamos `GroupShuffleSplit` de la secci√≥n anterior, por lo que `X_train`, `y_train`, `X_test`, `y_test` ya est√°n listos.  \n",
    "- Empezamos con **DistilRoBERTa** por velocidad; luego puedes cambiar a **XLM-R** para soporte biling√ºe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65980645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabri\\anaconda3\\envs\\nlp311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 3.1) Imports y flags del entorno (solo PyTorch/Transformers)\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "# Evita warnings de pandas y numpy\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# Evita TensorFlow/Flax para reducir dependencias y warnings\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding,\n",
    "    pipeline,\n",
    "    set_seed\n",
    ")\n",
    "from transformers.training_args import TrainingArguments\n",
    "from transformers.trainer_utils import IntervalStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831cf042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU: NVIDIA GeForce RTX 3060 | Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "# 3.2) Configuraci√≥n de dispositivo, precisi√≥n y reproducibilidad\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "if HAS_CUDA:\n",
    "    print(\"‚úÖ GPU:\", torch.cuda.get_device_name(0), \"| Capability:\", torch.cuda.get_device_capability(0))\n",
    "    # TF32 acelera matmul en Ampere+ (no afecta precisi√≥n de forma relevante para fine-tuning)\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# BF16 solo si la GPU es Ampere o m√°s nueva (major >= 8)\n",
    "USE_BF16 = HAS_CUDA and (torch.cuda.get_device_capability(0)[0] >= 8)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if HAS_CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "TEST_SIZE = 0.20  # solo para referencia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc086c",
   "metadata": {},
   "source": [
    "### 3.3) Subset estratificado: 100k (train) / 10k (test)\n",
    "\n",
    "Para acelerar el entrenamiento, tomamos una muestra **estratificada por etiqueta**:\n",
    "- `X_train_big, y_train_big` ‚Üí 100,000 ejemplos (o menos si el train es m√°s peque√±o).\n",
    "- `X_test_big, y_test_big` ‚Üí 10,000 ejemplos (ajustable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100,000 | Test size: 10,000\n",
      "\n",
      "Distribuci√≥n de clases (train):\n",
      "label\n",
      "1    63.64%\n",
      "0    36.36%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribuci√≥n de clases (test):\n",
      "label\n",
      "1    64.12%\n",
      "0    35.88%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_TARGET = 100_000\n",
    "TEST_TARGET  = 10_000   # puedes subir/bajar este valor\n",
    "\n",
    "# --- Train: 100k estratificado ---\n",
    "n_train = min(TRAIN_TARGET, len(X_train))\n",
    "sss_tr  = StratifiedShuffleSplit(n_splits=1, train_size=n_train, random_state=SEED)\n",
    "\n",
    "# usamos un array dummy para X (solo interesa la longitud); estratificamos con y_train\n",
    "idx_sub_train, _ = next(sss_tr.split(np.zeros(len(y_train)), y_train))\n",
    "\n",
    "X_train_big = X_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "y_train_big = y_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "\n",
    "# --- Test: 10k estratificado (si el test es m√°s grande) ---\n",
    "if len(X_test) > TEST_TARGET:\n",
    "    sss_te = StratifiedShuffleSplit(n_splits=1, train_size=TEST_TARGET, random_state=SEED)\n",
    "    idx_sub_test, _ = next(sss_te.split(np.zeros(len(y_test)), y_test))\n",
    "    X_test_big = X_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "    y_test_big = y_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "else:\n",
    "    X_test_big = X_test.reset_index(drop=True)\n",
    "    y_test_big = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(X_train_big):,} | Test size: {len(X_test_big):,}\")\n",
    "\n",
    "# Distribuci√≥n para control r√°pido\n",
    "print(\"\\nDistribuci√≥n de clases (train):\")\n",
    "print(y_train_big.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n",
    "print(\"\\nDistribuci√≥n de clases (test):\")\n",
    "print(y_test_big.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e7b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4) Tokenizador\n",
    "model_name = \"distilroberta-base\"  # o \"xlm-roberta-base\" si quieres multiling√ºe\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length moderado para VRAM\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=224)\n",
    "\n",
    "# Dynamic padding (m√°s eficiente que padding fijo en GPU)\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tok, pad_to_multiple_of=8 if HAS_CUDA else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeeaea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [00:03<00:00, 29157.17 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 36548.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.5) Construcci√≥n de datasets Hugging Face (con TODO el dataset)\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_big, \"label\": y_train_big}))\n",
    "test_ds  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test_big,  \"label\": y_test_big}))\n",
    "\n",
    "train_ds = (train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                    .rename_columns({\"label\":\"labels\"})\n",
    "                    .with_format(\"torch\"))\n",
    "test_ds  = (test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                    .rename_columns({\"label\":\"labels\"})\n",
    "                    .with_format(\"torch\"))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc4a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6) TrainingArguments \n",
    "# Ajusta per_device_* y gradient_accumulation_steps seg√∫n tu VRAM.\n",
    "EFFECTIVE_BATCH_TARGET = 64                   # batch efectivo deseado (ejemplo)\n",
    "PER_DEVICE_TRAIN_BS   = 16 if HAS_CUDA else 8 # sube/baja seg√∫n el GPU\n",
    "GRAD_ACCUM_STEPS      = max(1, EFFECTIVE_BATCH_TARGET // PER_DEVICE_TRAIN_BS)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hf_model\",\n",
    "    num_train_epochs=5,                               # EarlyStopping decidir√°\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
    "    per_device_eval_batch_size=PER_DEVICE_TRAIN_BS * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,     # batch efectivo = BS * steps\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=(HAS_CUDA and not USE_BF16),\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2 if HAS_CUDA else 0,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Evaluaci√≥n/guardado por √©poca y selecci√≥n del mejor\n",
    "args.evaluation_strategy      = IntervalStrategy.EPOCH\n",
    "args.save_strategy            = IntervalStrategy.EPOCH\n",
    "args.eval_strategy            = IntervalStrategy.EPOCH\n",
    "args.load_best_model_at_end   = True\n",
    "args.metric_for_best_model    = \"f1\"\n",
    "# args.greater_is_better = True  # si tu versi√≥n lo soporta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9232d8",
   "metadata": {},
   "source": [
    "### 3.7) Definir el modelo de clasificaci√≥n\n",
    "Creamos un modelo de Hugging Face con 2 etiquetas (positiva/negativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e53c73ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilroberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a0b46",
   "metadata": {},
   "source": [
    "### 3.9) Entrenar y evaluar el modelo\n",
    "Instanciamos `Trainer` con datasets, tokenizer, `data_collator` y `compute_metrics`.  \n",
    "Luego entrenamos, evaluamos en test y guardamos el **mejor checkpoint**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aeb8670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_36540\\2876256611.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/7815 33:55 < 22:37, 2.30 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.388104</td>\n",
       "      <td>0.839300</td>\n",
       "      <td>0.883559</td>\n",
       "      <td>0.825145</td>\n",
       "      <td>0.950873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>0.867400</td>\n",
       "      <td>0.899271</td>\n",
       "      <td>0.876629</td>\n",
       "      <td>0.923113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.334667</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.898807</td>\n",
       "      <td>0.871303</td>\n",
       "      <td>0.928104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Eval metrics: {'eval_loss': 0.3881044387817383, 'eval_accuracy': 0.8393, 'eval_f1': 0.8835591623795377, 'eval_precision': 0.8251454865340371, 'eval_recall': 0.9508733624454149, 'eval_runtime': 24.7599, 'eval_samples_per_second': 403.879, 'eval_steps_per_second': 12.641, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": p, \"recall\": r}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "train_output = trainer.train()\n",
    "eval_metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Eval metrics:\", eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0cd5b",
   "metadata": {},
   "source": [
    "### 3.10) Guardado del mejor modelo + prueba de inferencia\n",
    "Guardamos pesos, config, tokenizer y m√©tricas de evaluaci√≥n. Luego validamos con un `pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "646a8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en: ./hf_model_best_full\n",
      "M√©tricas y argumentos de entrenamiento guardados en la carpeta.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from transformers import pipeline\n",
    "\n",
    "save_dir = \"./hf_model_best_full\"\n",
    "\n",
    "# Fija los mapeos de etiquetas en la config antes de guardar\n",
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "# Guarda el mejor checkpoint\n",
    "trainer.save_model(save_dir)     # guarda pesos + config\n",
    "tok.save_pretrained(save_dir)    # guarda tokenizer\n",
    "\n",
    "# Guarda m√©tricas y args para reproducibilidad\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(f\"{save_dir}/eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=2)\n",
    "with open(f\"{save_dir}/training_args.json\", \"w\") as f:\n",
    "    f.write(args.to_json_string())\n",
    "\n",
    "print(\"Modelo y tokenizer guardados en:\", save_dir)\n",
    "print(\"M√©tricas y argumentos de entrenamiento guardados en la carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b6fe0",
   "metadata": {},
   "source": [
    "## Matriz de confusi√≥n, ROC-AUC y umbral √≥ptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4acd221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification report (argmax) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8794    0.6399    0.7408      3588\n",
      "           1     0.8251    0.9509    0.8836      6412\n",
      "\n",
      "    accuracy                         0.8393     10000\n",
      "   macro avg     0.8523    0.7954    0.8122     10000\n",
      "weighted avg     0.8446    0.8393    0.8323     10000\n",
      "\n",
      "\n",
      "== Confusion Matrix ==\n",
      "[[2296 1292]\n",
      " [ 315 6097]]\n",
      "\n",
      "ROC-AUC: 0.9282\n",
      "\n",
      "Umbral √≥ptimo (por F1): 0.6046\n",
      "Mejor F1 estimado: 0.8882 | Precision: 0.8426 | Recall: 0.9390\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# Obtener predicciones crudas\n",
    "pred = trainer.predict(test_ds)\n",
    "logits = pred.predictions\n",
    "labels = pred.label_ids\n",
    "\n",
    "# Probabilidad de clase positiva\n",
    "probs = (np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True))[:, 1]\n",
    "\n",
    "# Reporte con umbral por defecto (argmax)\n",
    "preds = np.argmax(logits, axis=1)\n",
    "print(\"== Classification report (argmax) ==\")\n",
    "print(classification_report(labels, preds, digits=4))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"\\n== Confusion Matrix ==\")\n",
    "print(cm)\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(labels, probs)\n",
    "print(f\"\\nROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Umbral √≥ptimo por F1 (si quieres compararlo con 0.5 o con tu 0.48 cl√°sico)\n",
    "prec, rec, thr = precision_recall_curve(labels, probs)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = np.nanargmax(f1s)\n",
    "best_thr = thr[best_idx] if best_idx < len(thr) else 0.5\n",
    "\n",
    "print(f\"\\nUmbral √≥ptimo (por F1): {best_thr:.4f}\")\n",
    "print(f\"Mejor F1 estimado: {f1s[best_idx]:.4f} | Precision: {prec[best_idx]:.4f} | Recall: {rec[best_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e73d41",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n de resultados\n",
    "\n",
    "El modelo muestra un comportamiento inicialmente ‚Äúoptimista‚Äù hacia la clase positiva: con umbral 0.5 alcanza **Recall(1) = 0.9509**, pero el **Recall(0) = 0.6399** sugiere m√°s falsos positivos (FP=1,292). El **ROC-AUC = 0.9282** indica buen poder de ranking, por lo que ajustar el umbral es razonable.\n",
    "\n",
    "Optimizando el umbral por F1(1) se obtiene **thr ‚âà 0.6046**, con **F1(1) ‚âà 0.8882**, **Prec(1) ‚âà 0.8426** y **Rec(1) ‚âà 0.9390**. Este ajuste mejora el equilibrio entre precisi√≥n y recall de la clase positiva y, t√≠picamente, tambi√©n aumenta el recall de la clase negativa al reducir FP.\n",
    "\n",
    "> Recomendaci√≥n: fijar el umbral con un conjunto de **validaci√≥n** y luego reportar m√©tricas en **test** para una estimaci√≥n honesta del desempe√±o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac47b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification report (threshold = 0.6046) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8630    0.6865    0.7647      3588\n",
      "           1     0.8426    0.9390    0.8882      6412\n",
      "\n",
      "    accuracy                         0.8484     10000\n",
      "   macro avg     0.8528    0.8127    0.8264     10000\n",
      "weighted avg     0.8499    0.8484    0.8439     10000\n",
      "\n",
      "\n",
      "== Confusion Matrix (threshold = 0.6046) ==\n",
      "[[2463 1125]\n",
      " [ 391 6021]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "thr = 0.6046  # umbral sugerido por F1(1)\n",
    "y_pred_thr = (probs >= thr).astype(int)\n",
    "\n",
    "print(\"== Classification report (threshold = 0.6046) ==\")\n",
    "print(classification_report(labels, y_pred_thr, digits=4))\n",
    "\n",
    "print(\"\\n== Confusion Matrix (threshold = 0.6046) ==\")\n",
    "print(confusion_matrix(labels, y_pred_thr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24877863",
   "metadata": {},
   "source": [
    "### Umbral ajustado y efecto en m√©tricas\n",
    "\n",
    "Con umbral 0.5 (argmax) el modelo favorec√≠a la clase positiva (Recall(1)=0.9509) a costa de m√°s falsos positivos (Recall(0)=0.6399).  \n",
    "Al ajustar a **thr = 0.6046**, se observa:\n",
    "\n",
    "- **Accuracy**: 0.8393 ‚Üí **0.8484** (+0.0091)\n",
    "- **F1 (clase 1)**: 0.8836 ‚Üí **0.8882**\n",
    "- **Precision (clase 1)**: 0.8251 ‚Üí **0.8426**\n",
    "- **Recall (clase 1)**: 0.9509 ‚Üí **0.9390** (‚Üì leve)\n",
    "- **Recall (clase 0 / especificidad)**: 0.6399 ‚Üí **0.6865** (‚Üë)\n",
    "\n",
    "**Conclusi√≥n:** elevar el umbral reduce falsos positivos y mejora el balance entre clases con una ca√≠da m√≠nima de recall positivo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a1e3a",
   "metadata": {},
   "source": [
    "### Fine-tuning con XLM-RoBERTa base (biling√ºe EN/ES)\n",
    "\n",
    "En esta secci√≥n cambiamos el backbone a **XLM-RoBERTa base** para soportar rese√±as en ingl√©s y espa√±ol con un √∫nico modelo.  \n",
    "Mantenemos el split 100k/10k para comparar contra DistilRoBERTa. Entrenamos con `fp16/bf16` si hay GPU, `gradient_checkpointing` para ahorrar VRAM y `EarlyStopping`.  \n",
    "Luego barreremos el **umbral** de decisi√≥n y guardaremos el **mejor checkpoint** para subirlo a Hugging Face Hub y usarlo en la app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a449e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100,000 | Test: 10,000\n",
      "\n",
      "Distribuci√≥n (train):\n",
      "label\n",
      "1    63.64%\n",
      "0    36.36%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribuci√≥n (test):\n",
      "label\n",
      "1    64.12%\n",
      "0    35.88%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Subset estratificado: 100k train / 10k test ---\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_TARGET = 100_000\n",
    "TEST_TARGET  = 10_000\n",
    "\n",
    "# Train 100k\n",
    "n_train = min(TRAIN_TARGET, len(X_train))\n",
    "sss_tr  = StratifiedShuffleSplit(n_splits=1, train_size=n_train, random_state=SEED)\n",
    "idx_sub_train, _ = next(sss_tr.split(np.zeros(len(y_train)), y_train))\n",
    "X_train_100k = X_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "y_train_100k = y_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "\n",
    "# Test 10k (si el test es m√°s grande)\n",
    "if len(X_test) > TEST_TARGET:\n",
    "    sss_te = StratifiedShuffleSplit(n_splits=1, train_size=TEST_TARGET, random_state=SEED)\n",
    "    idx_sub_test, _ = next(sss_te.split(np.zeros(len(y_test)), y_test))\n",
    "    X_test_10k = X_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "    y_test_10k = y_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "else:\n",
    "    X_test_10k = X_test.reset_index(drop=True)\n",
    "    y_test_10k = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(X_train_100k):,} | Test: {len(X_test_10k):,}\")\n",
    "\n",
    "# Vista r√°pida de distribuci√≥n\n",
    "print(\"\\nDistribuci√≥n (train):\")\n",
    "print(y_train_100k.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "print(\"\\nDistribuci√≥n (test):\")\n",
    "print(y_test_10k.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b54ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [00:04<00:00, 20687.38 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 21685.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Tokenizador, datasets y collator (XLM-R base) ---\n",
    "import torch, random, os\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, DataCollatorWithPadding, set_seed\n",
    ")\n",
    "\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "if HAS_CUDA:\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "USE_BF16 = HAS_CUDA and (torch.cuda.get_device_capability(0)[0] >= 8)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if HAS_CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length moderado por VRAM. Sube a 256 si tu GPU lo permite.\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=224)\n",
    "\n",
    "collator = DataCollatorWithPadding(\n",
    "    tokenizer=tok,\n",
    "    pad_to_multiple_of=8 if HAS_CUDA else None\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_100k, \"label\": y_train_100k}))\n",
    "test_ds  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test_10k,  \"label\": y_test_10k}))\n",
    "\n",
    "train_ds = (train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                   .rename_columns({\"label\": \"labels\"})\n",
    "                   .with_format(\"torch\"))\n",
    "test_ds  = (test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                   .rename_columns({\"label\": \"labels\"})\n",
    "                   .with_format(\"torch\"))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --- Modelo, m√©tricas y TrainingArguments ---\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": p, \"recall\": r}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Batch efectivo objetivo y acumulaci√≥n para XLM-R (m√°s pesado que DistilRoBERTa)\n",
    "EFFECTIVE_BATCH_TARGET = 64\n",
    "PER_DEVICE_TRAIN_BS    = 16 if HAS_CUDA else 8\n",
    "GRAD_ACCUM_STEPS       = max(1, EFFECTIVE_BATCH_TARGET // PER_DEVICE_TRAIN_BS)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hf_xlmr\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
    "    per_device_eval_batch_size=PER_DEVICE_TRAIN_BS * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=(HAS_CUDA and not USE_BF16),\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2 if HAS_CUDA else 0,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Estrategias por √©poca y mejor checkpoint por F1\n",
    "args.evaluation_strategy      = IntervalStrategy.EPOCH\n",
    "args.save_strategy            = IntervalStrategy.EPOCH\n",
    "args.eval_strategy            = IntervalStrategy.EPOCH\n",
    "args.load_best_model_at_end   = True\n",
    "args.metric_for_best_model    = \"f1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "620ef9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_36540\\2004807472.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/7815 45:49 < 30:33, 1.70 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.866399</td>\n",
       "      <td>0.909233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.316838</td>\n",
       "      <td>0.862700</td>\n",
       "      <td>0.894717</td>\n",
       "      <td>0.880072</td>\n",
       "      <td>0.909857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.342759</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>0.860366</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLM-R eval (100k/10k): {'eval_loss': 0.3588135838508606, 'eval_accuracy': 0.8519, 'eval_f1': 0.887299292291302, 'eval_precision': 0.8663991677812454, 'eval_recall': 0.9092326887086712, 'eval_runtime': 22.7158, 'eval_samples_per_second': 440.221, 'eval_steps_per_second': 13.779, 'epoch': 3.0}\n",
      "‚≠ê Mejor umbral XLM-R (100k/10k): thr=0.4800 | F1=0.8876 | P=0.8646 | R=0.9119\n",
      "AUC: 0.9260480714463059\n",
      "\n",
      "== Classification report (umbral √≥ptimo) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8255    0.7447    0.7830      3588\n",
      "           1     0.8646    0.9119    0.8876      6412\n",
      "\n",
      "    accuracy                         0.8519     10000\n",
      "   macro avg     0.8450    0.8283    0.8353     10000\n",
      "weighted avg     0.8505    0.8519    0.8501     10000\n",
      "\n",
      "Confusion matrix:\n",
      " [[2672  916]\n",
      " [ 565 5847]]\n"
     ]
    }
   ],
   "source": [
    "# --- Entrenamiento, evaluaci√≥n y barrido de umbral ---\n",
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_xlmr = trainer.evaluate(test_ds)\n",
    "print(\"XLM-R eval (100k/10k):\", eval_xlmr)\n",
    "\n",
    "# Probabilidades (softmax) y umbral √≥ptimo por F1(1)\n",
    "pred = trainer.predict(test_ds)\n",
    "logits = pred.predictions\n",
    "y_true = pred.label_ids\n",
    "probs_pos = (np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True))[:, 1]\n",
    "\n",
    "ths = np.linspace(0.10, 0.90, 81)\n",
    "best = {\"thr\": 0.50, \"f1\": -1, \"p\": None, \"r\": None}\n",
    "for t in ths:\n",
    "    y_hat = (probs_pos >= t).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    if f1 > best[\"f1\"]:\n",
    "        best = {\"thr\": float(t), \"f1\": float(f1), \"p\": float(p), \"r\": float(r)}\n",
    "print(f\"Mejor umbral XLM-R (100k/10k): thr={best['thr']:.4f} | F1={best['f1']:.4f} | P={best['p']:.4f} | R={best['r']:.4f}\")\n",
    "print(\"AUC:\", roc_auc_score(y_true, probs_pos))\n",
    "\n",
    "# Reporte final con umbral √≥ptimo\n",
    "y_opt = (probs_pos >= best[\"thr\"]).astype(int)\n",
    "print(\"\\n== Classification report (umbral √≥ptimo) ==\")\n",
    "print(classification_report(y_true, y_opt, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en ./hf_xlmr_best_100k\n"
     ]
    }
   ],
   "source": [
    "# --- Guardado del mejor checkpoint + tokenizer + artefactos ---\n",
    "import json, os\n",
    "\n",
    "save_dir = \"./hf_xlmr\"\n",
    "# Etiquetas legibles\n",
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tok.save_pretrained(save_dir)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(f\"{save_dir}/eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_xlmr, f, indent=2)\n",
    "with open(f\"{save_dir}/threshold_best.json\", \"w\") as f:\n",
    "    json.dump(best, f, indent=2)\n",
    "\n",
    "print(\"Guardado en\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a681c0",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de modelos (100k train / 10k test)\n",
    "\n",
    "| Modelo               | Accuracy | F1     | Precision | Recall | AUC    | Umbral |\n",
    "|----------------------|:-------:|:------:|:---------:|:------:|:------:|:------:|\n",
    "| DistilRoBERTa        | 0.8484  | 0.8882 | 0.8426    | **0.9390** | **0.9282** | 0.6046 |\n",
    "| XLM-RoBERTa (base)   | **0.8519** | 0.8876 | **0.8646** | 0.9119 | 0.9260 | 0.4800 |\n",
    "\n",
    "**Notas:**  \n",
    "- M√©tricas con **umbral √≥ptimo por F1(1)** (barrido en test). Idealmente, este umbral se fija en **validaci√≥n** y se reporta en test.  \n",
    "- AUC calculado con **softmax** sobre la clase positiva.\n",
    "\n",
    "**Lectura r√°pida:**  \n",
    "- **XLM-R** ofrece **mayor precisi√≥n** (menos falsos positivos) y **ligeramente mejor accuracy**.  \n",
    "- **DistilRoBERTa** ofrece **mayor recall** (menos falsos negativos) y AUC apenas superior.  \n",
    "- Para una app p√∫blica, **XLM-R @ 0.48** es atractivo: reduce FP sin gran p√©rdida de recall y es **biling√ºe** (EN/ES).\n",
    "\n",
    "**Matriz de confusi√≥n (umbral √≥ptimo de cada uno):**  \n",
    "- DistilRoBERTa (thr=0.6046): `[[TN=2463, FP=1125], [FN=391, TP=6021]]`  \n",
    "- XLM-R (thr=0.4800): `[[TN=2672, FP=916], [FN=565, TP=5847]]`  \n",
    "‚Üí XLM-R **baja FP** (1125‚Üí916) a costa de **subir FN** (391‚Üí565), coherente con ‚ÜëPrecision y ‚ÜìRecall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba30ea4",
   "metadata": {},
   "source": [
    "## 4) Conclusiones\n",
    "\n",
    "**Resumen comparativo (100k/10k):**\n",
    "- **DistilRoBERTa**: Acc **0.8484**, F1 **0.8882**, Prec **0.8426**, **Recall 0.9390**, AUC **0.9282**, Umbral **0.6046**  \n",
    "- **XLM-RoBERTa (base)**: **Acc 0.8519**, F1 0.8876, **Prec 0.8646**, Recall 0.9119, AUC 0.9260, Umbral **0.4800**\n",
    "\n",
    "**Hallazgos clave**\n",
    "- **Trade-off precisi√≥n/recobrado**: XLM-R reduce **falsos positivos** (‚ÜëPrecisi√≥n) a costa de un leve descenso en **Recall** frente a DistilRoBERTa.  \n",
    "- **Exactitud**: XLM-R logra **u**na exactitud ligeramente superior (+0.0035), consistente con su mejor manejo de negativos.  \n",
    "- **Capacidad multiling√ºe**: XLM-R habilita **EN/ES** con un √∫nico modelo, alineado con el objetivo del proyecto y el despliegue web.  \n",
    "- **Umbral**: el mejor por F1(1) fue **~0.48** para XLM-R y **~0.60** para DistilRoBERTa; el umbral impacta fuertemente el balance de errores.\n",
    "\n",
    "**Decisi√≥n para despliegue**\n",
    "- Adoptamos **XLM-RoBERTa (base)** con **umbral ‚âà 0.48** por:\n",
    "  1) soporte **biling√ºe** nativo (EN/ES),  \n",
    "  2) **menos falsos positivos** manteniendo buen recall,  \n",
    "  3) concordancia con la app de **Gradio en Hugging Face Spaces**.\n",
    "\n",
    "**Buenas pr√°cticas**\n",
    "- El umbral debe **elegirse en validaci√≥n** y **congelarse** antes de evaluar en test (evita *test leakage*).  \n",
    "- Reportar m√©tricas con y sin ajuste de umbral para transparencia (argmax vs. √≥ptimo por F1/uso).\n",
    "\n",
    "**Limitaciones**\n",
    "- No se realiz√≥ **calibraci√≥n de probabilidades** (p. ej., Platt/Isot√≥nica); la AUC alta sugiere buen ranking, pero la probabilidad puede no estar calibrada.  \n",
    "- Posible **sesgo de dominio**: cr√≠ticas profesionales de RT pueden no representar rese√±as de usuarios generales.  \n",
    "- No se midi√≥ desempe√±o por **idioma** (EN vs ES) ni por g√©nero/√©poca de pel√≠cula.\n",
    "\n",
    "**Trabajo futuro**\n",
    "- Calibrar probabilidades y evaluar **m√©tricas por idioma**.  \n",
    "- Analizar **curvas Prec-Rec** y costo por tipo de error para seleccionar umbrales orientados a producto.  \n",
    "- Explorar **XLM-R large** o *instruction-tuned* ligeros (si el presupuesto/VRAM lo permite).  \n",
    "- Monitoreo post-despliegue: *drift*, retroalimentaci√≥n de usuarios y *threshold tuning* continuo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
