{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007d9518",
   "metadata": {},
   "source": [
    "# Analizador de Sentimiento Bilingüe en Reseñas de Películas (EN/ES) con XLM-R\n",
    "\n",
    "\n",
    "Este trabajo es una **extensión y mejora** de *“Análisis de Reseñas de Rotten Tomatoes con NLP”* (donde se usó un modelo clásico de **Regresión Logística**, Acc≈81% sobre >1M reseñas).  \n",
    "Aquí migramos a arquitecturas **Transformers**, comparamos **DistilRoBERTa** (baseline rápido) con **XLM-RoBERTa base (XLM-R)** para soporte **bilingüe EN/ES**, y **desplegamos** el mejor sistema como una aplicación accesible (Gradio en Hugging Face Spaces).\n",
    "\n",
    "Usamos un split *group-aware por película* y un escenario de comparación **100k/10k** (train/test) para iteración rápida. Además, ajustamos el **umbral de decisión** para equilibrar precisión/recobrado en uso real.\n",
    "\n",
    "**Resultados:**\n",
    "- **DistilRoBERTa** → Acc **0.8484** · F1 **0.8882** · Prec 0.8426 · **Rec 0.9390** · AUC **0.9282** · *thr≈0.6046*  \n",
    "- **XLM-R (base)** → **Acc 0.8519** · F1 0.8876 · **Prec 0.8646** · Rec 0.9119 · AUC 0.9260 · *thr≈0.4800*  \n",
    "\n",
    "**Conclusión:** \n",
    "XLM-R ofrece **menor tasa de falsos positivos** (↑Precisión) con exactitud ligeramente superior, manteniendo un recall alto y habilitando **bilingüismo**; por ello es el modelo elegido para despliegue (umbral operativo ≈ **0.48**).\n",
    "\n",
    "---\n",
    "\n",
    "## Metodología\n",
    "1. **Datos**: reseñas de críticos de *Rotten Tomatoes* (Kaggle; >1M).  \n",
    "2. **Preprocesamiento**:\n",
    "   - Auto-detección de columnas (texto/etiqueta/agrupador) y **limpieza mínima** (HTML, espacios, contracciones).\n",
    "   - Normalización de etiqueta binaria (`Fresh`/`Rotten` → {1,0}).\n",
    "3. **Partición**:\n",
    "   - **GroupShuffleSplit** por película (evita fuga de información por título).\n",
    "   - Submuestreo estratificado para escenarios **50k/10k** y **100k/10k**.\n",
    "4. **Modelado**:\n",
    "   - **DistilRoBERTa** (baseline rápido, EN).\n",
    "   - **XLM-R base** (modelo principal, **EN/ES**).\n",
    "   - Entrenamiento con `fp16/bf16` (según GPU), `gradient_checkpointing`, `cosine` scheduler, `EarlyStopping`.\n",
    "5. **Evaluación**:\n",
    "   - `Accuracy`, `F1`, `Precision`, `Recall`, `ROC-AUC`.\n",
    "   - Barrido de **umbral** y reporte de matriz de confusión.\n",
    "6. **Despliegue**:\n",
    "   - App **Gradio** en Hugging Face Spaces.\n",
    "   - **API** autoexpuesta con endpoints `/predict_single` y `/predict_batch`.\n",
    "\n",
    "---\n",
    "\n",
    "> **Modelo en despliegue:** XLM-R base (EN/ES), umbral operativo ≈ **0.48**, consumido por la app Gradio y su API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Librerías estandar =====\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from typing import Any, Dict, Iterable, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "# Silenciar warnings \n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del CSV: ['rotten_tomatoes_link', 'critic_name', 'top_critic', 'publisher_name', 'review_type', 'review_score', 'review_date', 'review_content']\n"
     ]
    }
   ],
   "source": [
    "# Lectura CSV \n",
    "df = pd.read_csv('data/rotten_tomatoes_critic_reviews.csv')\n",
    "\n",
    "# Inspección rápida de columnas disponibles \n",
    "print(\"Columnas del CSV:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9435ab",
   "metadata": {},
   "source": [
    "### 1) Preparación del Dataset (Limpieza y Estandarización)\n",
    "\n",
    "\n",
    "- Definimos directamente los nombres de las columnas de texto, etiqueta y grupo. \n",
    "\n",
    "- Aplicamos una limpieza básica a las reseñas para eliminar ruido, como etiquetas HTML, y para normalizar los espacios en blanco.\n",
    "\n",
    "- Convertimos las etiquetas de texto (ej. 'fresh'/'rotten') a un formato numérico binario (1 para Positivo, 0 para Negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f157c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos explícitamente las columnas con las que trabajaremos\n",
    "TEXT_COL = 'review_content'   # Contiene el texto de la reseña\n",
    "LABEL_COL = 'review_type'      # Probablemente contiene \"fresh\" o \"rotten\"\n",
    "GROUP_COL = 'rotten_tomatoes_link' # Identificador único para agrupar por película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93120d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando la columna 'review_content'...\n",
      "Limpieza de texto completada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's really lacking in The Lightning Thief i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_clean\n",
       "0  A fantasy adventure that fuses Greek mythology...\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...\n",
       "2  With a top-notch cast and dazzling special eff...\n",
       "3  Whether audiences will get behind The Lightnin...\n",
       "4  What's really lacking in The Lightning Thief i..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos una copia para no modificar el DataFrame original\n",
    "df_limpio = df.copy()\n",
    "\n",
    "# Limpiamos la columna de texto de forma secuencial\n",
    "print(f\"Limpiando la columna '{TEXT_COL}'...\")\n",
    "\n",
    "# Quitar etiquetas HTML y convertir entidades HTML (ej: &amp; -> &)\n",
    "df_limpio['review_clean'] = df_limpio[TEXT_COL].astype(str).apply(html.unescape)\n",
    "df_limpio['review_clean'] = df_limpio['review_clean'].str.replace(r'<[^>]+>', ' ', regex=True)\n",
    "\n",
    "# Normalizar espacios en blanco (múltiples espacios, saltos de línea) a uno solo\n",
    "df_limpio['review_clean'] = df_limpio['review_clean'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(\"Limpieza de texto completada.\")\n",
    "df_limpio[['review_clean']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77289c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando la columna de etiquetas 'review_type'...\n",
      "Etiquetas normalizadas.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentimiento\n",
       "1    720210\n",
       "0    409807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos las etiquetas de texto a números (0 o 1)\n",
    "print(f\"Normalizando la columna de etiquetas '{LABEL_COL}'...\")\n",
    "\n",
    "# Mapa simple para convertir 'fresh' a 1 y 'rotten' a 0\n",
    "label_map = {\n",
    "    'fresh': 1,\n",
    "    'rotten': 0\n",
    "}\n",
    "\n",
    "# Usamos .str.lower() para ignorar mayúsculas y .map() para aplicar la conversión\n",
    "df_limpio['sentimiento'] = df_limpio[LABEL_COL].str.lower().map(label_map)\n",
    "\n",
    "print(\"Etiquetas normalizadas.\")\n",
    "df_limpio['sentimiento'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65b191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final creado. Se eliminaron 0 filas con datos nulos.\n",
      "\n",
      ">> Muestra del DataFrame final:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>group_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's really lacking in The Lightning Thief i...</td>\n",
       "      <td>0</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_clean  sentimiento  group_key\n",
       "0  A fantasy adventure that fuses Greek mythology...            1  m/0814255\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...            1  m/0814255\n",
       "2  With a top-notch cast and dazzling special eff...            1  m/0814255\n",
       "3  Whether audiences will get behind The Lightnin...            1  m/0814255\n",
       "4  What's really lacking in The Lightning Thief i...            0  m/0814255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Distribución de la etiqueta:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentimiento</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "sentimiento        \n",
       "1            720210\n",
       "0            409807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seleccionamos y renombramos las columnas para nuestro modelo\n",
    "df_final = df_limpio[\n",
    "    ['review_clean', 'sentimiento', GROUP_COL]\n",
    "].copy()\n",
    "\n",
    "# Renombramos la columna de agrupación para que sea estándar\n",
    "df_final = df_final.rename(columns={GROUP_COL: 'group_key'})\n",
    "\n",
    "# Eliminamos filas donde la limpieza falló o la etiqueta no se pudo convertir\n",
    "rows_before = len(df_final)\n",
    "df_final.dropna(inplace=True)\n",
    "rows_after = len(df_final)\n",
    "\n",
    "# Convertimos la etiqueta a entero, ya que no hay nulos\n",
    "df_final['sentimiento'] = df_final['sentimiento'].astype(int)\n",
    "\n",
    "\n",
    "print(f\"DataFrame final creado. Se eliminaron {rows_before - rows_after} filas con datos nulos.\")\n",
    "print(\"\\n>> Muestra del DataFrame final:\")\n",
    "display(df_final.head())\n",
    "\n",
    "print(\"\\n>> Distribución de la etiqueta:\")\n",
    "display(df_final['sentimiento'].value_counts().to_frame('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7026b",
   "metadata": {},
   "source": [
    "### 2) Creación de los Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "Ahora que tenemos nuestros datos limpios y estandarizados en `df_final`, el siguiente paso es dividirlos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "**Objetivo principal:**\n",
    "Realizar una partición estratificada por grupos (`GroupShuffleSplit`) para asegurar que las reseñas de una misma película no se mezclen entre el conjunto de entrenamiento y el de prueba. Esto es crucial para evitar la fuga de datos (*data leakage*) y obtener una evaluación honesta del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44ebc5",
   "metadata": {},
   "source": [
    "> **Checklist**\n",
    "> - [x] `df_trf` estandarizado con `text`, `label`, `group`.\n",
    "> - [x] Split 80/20 **por película** con `GroupShuffleSplit`.\n",
    "> - [x] Sin solapamiento de `group` entre train y test.\n",
    "> - [x] `X_train`, `y_train`, `X_test`, `y_test` listos para evaluación del modelo final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7029ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame listo para la partición:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label      group\n",
       "0  A fantasy adventure that fuses Greek mythology...      1  m/0814255\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...      1  m/0814255\n",
       "2  With a top-notch cast and dazzling special eff...      1  m/0814255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Partimos del DataFrame limpio y estandarizado\n",
    "df_para_split = df_final.copy()\n",
    "\n",
    "# Renombramos las columnas a un formato genérico para el split\n",
    "df_para_split = df_para_split.rename(columns={\n",
    "    \"review_clean\": \"text\",\n",
    "    \"sentimiento\": \"label\",\n",
    "    \"group_key\": \"group\"\n",
    "})\n",
    "\n",
    "print(\"DataFrame listo para la partición:\")\n",
    "display(df_para_split.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4f147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partición completada.\n",
      "Tamaño del conjunto de entrenamiento: 908,582 filas\n",
      "Tamaño del conjunto de prueba: 221,435 filas\n"
     ]
    }
   ],
   "source": [
    "# Definimos la configuración para la partición\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Separamos los datos en X (entradas), y (etiquetas) y groups (agrupador)\n",
    "X_all = df_para_split[\"text\"]\n",
    "y_all = df_para_split[\"label\"]\n",
    "groups_all = df_para_split[\"group\"]\n",
    "\n",
    "# Inicializamos el divisor. Se asegura de que todos los datos de un 'group'\n",
    "# queden en train o en test, pero no en ambos.\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Obtenemos los índices para train y test\n",
    "train_idx, test_idx = next(gss.split(X_all, y_all, groups=groups_all))\n",
    "\n",
    "# Usamos los índices para crear los conjuntos finales\n",
    "X_train, X_test = X_all.iloc[train_idx], X_all.iloc[test_idx]\n",
    "y_train, y_test = y_all.iloc[train_idx], y_all.iloc[test_idx]\n",
    "\n",
    "print(f\"Partición completada.\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(X_train):,} filas\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(X_test):,} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd41e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reporte de la Partición:\n",
      " - Películas únicas en train: 14,169\n",
      " - Películas únicas en test: 3,543\n",
      " - Películas compartidas (solapamiento): 0\n",
      "\n",
      ">> Distribución de etiquetas en cada conjunto:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>578236</td>\n",
       "      <td>141974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330346</td>\n",
       "      <td>79461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train    test\n",
       "label                \n",
       "1      578236  141974\n",
       "0      330346   79461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificamos que no haya películas compartidas entre train y test\n",
    "grupos_train = set(groups_all.iloc[train_idx].unique())\n",
    "grupos_test = set(groups_all.iloc[test_idx].unique())\n",
    "solapamiento = grupos_train.intersection(grupos_test)\n",
    "\n",
    "print(\">> Reporte de la Partición:\")\n",
    "print(f\" - Películas únicas en train: {len(grupos_train):,}\")\n",
    "print(f\" - Películas únicas en test: {len(grupos_test):,}\")\n",
    "print(f\" - Películas compartidas (solapamiento): {len(solapamiento)}\")\n",
    "\n",
    "# Una aserción es una forma robusta de asegurar que la condición se cumple\n",
    "assert len(solapamiento) == 0, \"¡Error! Hay solapamiento de grupos entre train y test.\"\n",
    "\n",
    "print(\"\\n>> Distribución de etiquetas en cada conjunto:\")\n",
    "# Mostramos la distribución de clases para confirmar que es similar\n",
    "distribucion = pd.DataFrame({\n",
    "    'train': y_train.value_counts(),\n",
    "    'test': y_test.value_counts()\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "display(distribucion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587479d",
   "metadata": {},
   "source": [
    "### 3) Entrenamiento rápido del modelo baseline\n",
    "\n",
    "En esta sección entrenaremos un modelo de *Transformers* directamente sobre un **subset** (100k train / 10k test) para iterar rápido.  \n",
    "- Usamos `GroupShuffleSplit` de la sección anterior, por lo que `X_train`, `y_train`, `X_test`, `y_test` ya están listos.  \n",
    "- Empezamos con **DistilRoBERTa** por velocidad; luego puedes cambiar a **XLM-R** para soporte bilingüe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65980645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evita TensorFlow/Flax para reducir dependencias y warnings\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831cf042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3060 | Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "# Configuración de dispositivo, precisión y reproducibilidad\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "if HAS_CUDA:\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0), \"| Capability:\", torch.cuda.get_device_capability(0))\n",
    "    # TF32 acelera matmul en Ampere+ (no afecta precisión de forma relevante para fine-tuning)\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# BF16 solo si la GPU es Ampere o más nueva (major >= 8)\n",
    "USE_BF16 = HAS_CUDA and (torch.cuda.get_device_capability(0)[0] >= 8)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if HAS_CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "TEST_SIZE = 0.20  # solo para referencia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc086c",
   "metadata": {},
   "source": [
    "### Subset estratificado: 100k (train) / 10k (test)\n",
    "\n",
    "Para acelerar el entrenamiento, tomamos una muestra **estratificada por etiqueta**:\n",
    "- `X_train_big, y_train_big` → 100,000 ejemplos (o menos si el train es más pequeño).\n",
    "- `X_test_big, y_test_big` → 10,000 ejemplos (ajustable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100,000 | Test size: 10,000\n",
      "\n",
      "Distribución de clases (train):\n",
      "label\n",
      "1    63.64%\n",
      "0    36.36%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribución de clases (test):\n",
      "label\n",
      "1    64.12%\n",
      "0    35.88%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "TRAIN_TARGET = 100_000\n",
    "TEST_TARGET  = 10_000   # puedes subir/bajar este valor\n",
    "\n",
    "# --- Train: 100k estratificado ---\n",
    "n_train = min(TRAIN_TARGET, len(X_train))\n",
    "sss_tr  = StratifiedShuffleSplit(n_splits=1, train_size=n_train, random_state=SEED)\n",
    "\n",
    "# usamos un array dummy para X (solo interesa la longitud); estratificamos con y_train\n",
    "idx_sub_train, _ = next(sss_tr.split(np.zeros(len(y_train)), y_train))\n",
    "\n",
    "X_train_big = X_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "y_train_big = y_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "\n",
    "# --- Test: 10k estratificado (si el test es más grande) ---\n",
    "if len(X_test) > TEST_TARGET:\n",
    "    sss_te = StratifiedShuffleSplit(n_splits=1, train_size=TEST_TARGET, random_state=SEED)\n",
    "    idx_sub_test, _ = next(sss_te.split(np.zeros(len(y_test)), y_test))\n",
    "    X_test_big = X_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "    y_test_big = y_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "else:\n",
    "    X_test_big = X_test.reset_index(drop=True)\n",
    "    y_test_big = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(X_train_big):,} | Test size: {len(X_test_big):,}\")\n",
    "\n",
    "# Distribución para control rápido\n",
    "print(\"\\nDistribución de clases (train):\")\n",
    "print(y_train_big.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n",
    "print(\"\\nDistribución de clases (test):\")\n",
    "print(y_test_big.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizador\n",
    "model_name = \"distilroberta-base\"  # o \"xlm-roberta-base\" si quieres multilingüe\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length moderado para VRAM\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=224)\n",
    "\n",
    "# Dynamic padding (más eficiente que padding fijo en GPU)\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tok, pad_to_multiple_of=8 if HAS_CUDA else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeaea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100000/100000 [00:03<00:00, 29157.17 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 36548.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Construcción de datasets Hugging Face\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_big, \"label\": y_train_big}))\n",
    "test_ds  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test_big,  \"label\": y_test_big}))\n",
    "\n",
    "train_ds = (train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                    .rename_columns({\"label\":\"labels\"})\n",
    "                    .with_format(\"torch\"))\n",
    "test_ds  = (test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                    .rename_columns({\"label\":\"labels\"})\n",
    "                    .with_format(\"torch\"))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments \n",
    "EFFECTIVE_BATCH_TARGET = 64                   # batch efectivo deseado (ejemplo)\n",
    "PER_DEVICE_TRAIN_BS   = 16 if HAS_CUDA else 8 # sube/baja según el GPU\n",
    "GRAD_ACCUM_STEPS      = max(1, EFFECTIVE_BATCH_TARGET // PER_DEVICE_TRAIN_BS)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hf_model\",\n",
    "    num_train_epochs=5,                               # EarlyStopping decidirá\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
    "    per_device_eval_batch_size=PER_DEVICE_TRAIN_BS * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,     # batch efectivo = BS * steps\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=(HAS_CUDA and not USE_BF16),\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2 if HAS_CUDA else 0,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Evaluación/guardado por época y selección del mejor\n",
    "args.evaluation_strategy      = IntervalStrategy.EPOCH\n",
    "args.save_strategy            = IntervalStrategy.EPOCH\n",
    "args.eval_strategy            = IntervalStrategy.EPOCH\n",
    "args.load_best_model_at_end   = True\n",
    "args.metric_for_best_model    = \"f1\"\n",
    "# args.greater_is_better = True  # si tu versión lo soporta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9232d8",
   "metadata": {},
   "source": [
    "### Definir el modelo de clasificación\n",
    "Creamos un modelo de Hugging Face con 2 etiquetas (positiva/negativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c73ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilroberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a0b46",
   "metadata": {},
   "source": [
    "### Entrenar y evaluar el modelo\n",
    "Instanciamos `Trainer` con datasets, tokenizer, `data_collator` y `compute_metrics`.  \n",
    "Luego entrenamos, evaluamos en test y guardamos el **mejor checkpoint**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb8670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_36540\\2876256611.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/7815 33:55 < 22:37, 2.30 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.388104</td>\n",
       "      <td>0.839300</td>\n",
       "      <td>0.883559</td>\n",
       "      <td>0.825145</td>\n",
       "      <td>0.950873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>0.867400</td>\n",
       "      <td>0.899271</td>\n",
       "      <td>0.876629</td>\n",
       "      <td>0.923113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.334667</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.898807</td>\n",
       "      <td>0.871303</td>\n",
       "      <td>0.928104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Eval metrics: {'eval_loss': 0.3881044387817383, 'eval_accuracy': 0.8393, 'eval_f1': 0.8835591623795377, 'eval_precision': 0.8251454865340371, 'eval_recall': 0.9508733624454149, 'eval_runtime': 24.7599, 'eval_samples_per_second': 403.879, 'eval_steps_per_second': 12.641, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": p, \"recall\": r}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "train_output = trainer.train()\n",
    "eval_metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Eval metrics:\", eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0cd5b",
   "metadata": {},
   "source": [
    "### Guardado del mejor modelo y prueba de inferencia\n",
    "Guardamos pesos, config, tokenizer y métricas de evaluación. Luego validamos con un `pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en: ./hf_model_best_full\n",
      "Métricas y argumentos de entrenamiento guardados en la carpeta.\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./hf_model_best_full\"\n",
    "\n",
    "# Fija los mapeos de etiquetas en la config antes de guardar\n",
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "# Guarda el mejor checkpoint\n",
    "trainer.save_model(save_dir)     # guarda pesos + config\n",
    "tok.save_pretrained(save_dir)    # guarda tokenizer\n",
    "\n",
    "# Guarda métricas y args para reproducibilidad\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(f\"{save_dir}/eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=2)\n",
    "with open(f\"{save_dir}/training_args.json\", \"w\") as f:\n",
    "    f.write(args.to_json_string())\n",
    "\n",
    "print(\"Modelo y tokenizer guardados en:\", save_dir)\n",
    "print(\"Métricas y argumentos de entrenamiento guardados en la carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b6fe0",
   "metadata": {},
   "source": [
    "###  Matriz de confusión, ROC-AUC y umbral óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification report (argmax) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8794    0.6399    0.7408      3588\n",
      "           1     0.8251    0.9509    0.8836      6412\n",
      "\n",
      "    accuracy                         0.8393     10000\n",
      "   macro avg     0.8523    0.7954    0.8122     10000\n",
      "weighted avg     0.8446    0.8393    0.8323     10000\n",
      "\n",
      "\n",
      "== Confusion Matrix ==\n",
      "[[2296 1292]\n",
      " [ 315 6097]]\n",
      "\n",
      "ROC-AUC: 0.9282\n",
      "\n",
      "Umbral óptimo (por F1): 0.6046\n",
      "Mejor F1 estimado: 0.8882 | Precision: 0.8426 | Recall: 0.9390\n"
     ]
    }
   ],
   "source": [
    "# Obtener predicciones crudas\n",
    "pred = trainer.predict(test_ds)\n",
    "logits = pred.predictions\n",
    "labels = pred.label_ids\n",
    "\n",
    "# Probabilidad de clase positiva\n",
    "probs = (np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True))[:, 1]\n",
    "\n",
    "# Reporte con umbral por defecto (argmax)\n",
    "preds = np.argmax(logits, axis=1)\n",
    "print(\"== Classification report (argmax) ==\")\n",
    "print(classification_report(labels, preds, digits=4))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"\\n== Confusion Matrix ==\")\n",
    "print(cm)\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(labels, probs)\n",
    "print(f\"\\nROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Umbral óptimo por F1 (si quieres compararlo con 0.5 o con tu 0.48 clásico)\n",
    "prec, rec, thr = precision_recall_curve(labels, probs)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = np.nanargmax(f1s)\n",
    "best_thr = thr[best_idx] if best_idx < len(thr) else 0.5\n",
    "\n",
    "print(f\"\\nUmbral óptimo (por F1): {best_thr:.4f}\")\n",
    "print(f\"Mejor F1 estimado: {f1s[best_idx]:.4f} | Precision: {prec[best_idx]:.4f} | Recall: {rec[best_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e73d41",
   "metadata": {},
   "source": [
    "### Interpretación de resultados\n",
    "\n",
    "El modelo muestra un comportamiento inicialmente “optimista” hacia la clase positiva: con umbral 0.5 alcanza **Recall(1) = 0.9509**, pero el **Recall(0) = 0.6399** sugiere más falsos positivos (FP=1,292). El **ROC-AUC = 0.9282** indica buen poder de ranking, por lo que ajustar el umbral es razonable.\n",
    "\n",
    "Optimizando el umbral por F1(1) se obtiene **thr ≈ 0.6046**, con **F1(1) ≈ 0.8882**, **Prec(1) ≈ 0.8426** y **Rec(1) ≈ 0.9390**. Este ajuste mejora el equilibrio entre precisión y recall de la clase positiva y, típicamente, también aumenta el recall de la clase negativa al reducir FP.\n",
    "\n",
    "> Recomendación: fijar el umbral con un conjunto de **validación** y luego reportar métricas en **test** para una estimación honesta del desempeño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac47b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification report (threshold = 0.6046) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8630    0.6865    0.7647      3588\n",
      "           1     0.8426    0.9390    0.8882      6412\n",
      "\n",
      "    accuracy                         0.8484     10000\n",
      "   macro avg     0.8528    0.8127    0.8264     10000\n",
      "weighted avg     0.8499    0.8484    0.8439     10000\n",
      "\n",
      "\n",
      "== Confusion Matrix (threshold = 0.6046) ==\n",
      "[[2463 1125]\n",
      " [ 391 6021]]\n"
     ]
    }
   ],
   "source": [
    "thr = 0.6046  # umbral sugerido por F1(1)\n",
    "y_pred_thr = (probs >= thr).astype(int)\n",
    "\n",
    "print(\"== Classification report (threshold = 0.6046) ==\")\n",
    "print(classification_report(labels, y_pred_thr, digits=4))\n",
    "\n",
    "print(\"\\n== Confusion Matrix (threshold = 0.6046) ==\")\n",
    "print(confusion_matrix(labels, y_pred_thr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24877863",
   "metadata": {},
   "source": [
    "### Umbral ajustado y efecto en métricas\n",
    "\n",
    "Con umbral 0.5 (argmax) el modelo favorecía la clase positiva (Recall(1)=0.9509) a costa de más falsos positivos (Recall(0)=0.6399).  \n",
    "Al ajustar a **thr = 0.6046**, se observa:\n",
    "\n",
    "- **Accuracy**: 0.8393 → **0.8484** (+0.0091)\n",
    "- **F1 (clase 1)**: 0.8836 → **0.8882**\n",
    "- **Precision (clase 1)**: 0.8251 → **0.8426**\n",
    "- **Recall (clase 1)**: 0.9509 → **0.9390** (↓ leve)\n",
    "- **Recall (clase 0 / especificidad)**: 0.6399 → **0.6865** (↑)\n",
    "\n",
    "**Conclusión:** elevar el umbral reduce falsos positivos y mejora el balance entre clases con una caída mínima de recall positivo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a1e3a",
   "metadata": {},
   "source": [
    "### Fine-tuning con XLM-RoBERTa base (bilingüe EN/ES)\n",
    "\n",
    "En esta sección cambiamos el backbone a **XLM-RoBERTa base** para soportar reseñas en inglés y español con un único modelo.  \n",
    "Mantenemos el split 100k/10k para comparar contra DistilRoBERTa. Entrenamos con `fp16/bf16` si hay GPU, `gradient_checkpointing` para ahorrar VRAM y `EarlyStopping`.  \n",
    "Luego barreremos el **umbral** de decisión y guardaremos el **mejor checkpoint** para subirlo a Hugging Face Hub y usarlo en la app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a449e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100,000 | Test: 10,000\n",
      "\n",
      "Distribución (train):\n",
      "label\n",
      "1    63.64%\n",
      "0    36.36%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribución (test):\n",
      "label\n",
      "1    64.12%\n",
      "0    35.88%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Subset estratificado: 100k train / 10k test ---\n",
    "SEED = 42\n",
    "TRAIN_TARGET = 100_000\n",
    "TEST_TARGET  = 10_000\n",
    "\n",
    "# Train 100k\n",
    "n_train = min(TRAIN_TARGET, len(X_train))\n",
    "sss_tr  = StratifiedShuffleSplit(n_splits=1, train_size=n_train, random_state=SEED)\n",
    "idx_sub_train, _ = next(sss_tr.split(np.zeros(len(y_train)), y_train))\n",
    "X_train_100k = X_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "y_train_100k = y_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "\n",
    "# Test 10k (si el test es más grande)\n",
    "if len(X_test) > TEST_TARGET:\n",
    "    sss_te = StratifiedShuffleSplit(n_splits=1, train_size=TEST_TARGET, random_state=SEED)\n",
    "    idx_sub_test, _ = next(sss_te.split(np.zeros(len(y_test)), y_test))\n",
    "    X_test_10k = X_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "    y_test_10k = y_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "else:\n",
    "    X_test_10k = X_test.reset_index(drop=True)\n",
    "    y_test_10k = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(X_train_100k):,} | Test: {len(X_test_10k):,}\")\n",
    "\n",
    "# Vista rápida de distribución\n",
    "print(\"\\nDistribución (train):\")\n",
    "print(y_train_100k.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "print(\"\\nDistribución (test):\")\n",
    "print(y_test_10k.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b54ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100000/100000 [00:04<00:00, 20687.38 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 21685.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- XLM-R base ---\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "if HAS_CUDA:\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "USE_BF16 = HAS_CUDA and (torch.cuda.get_device_capability(0)[0] >= 8)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if HAS_CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length moderado por VRAM. Sube a 256 si tu GPU lo permite.\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=224)\n",
    "\n",
    "collator = DataCollatorWithPadding(\n",
    "    tokenizer=tok,\n",
    "    pad_to_multiple_of=8 if HAS_CUDA else None\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_100k, \"label\": y_train_100k}))\n",
    "test_ds  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test_10k,  \"label\": y_test_10k}))\n",
    "\n",
    "train_ds = (train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                   .rename_columns({\"label\": \"labels\"})\n",
    "                   .with_format(\"torch\"))\n",
    "test_ds  = (test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                   .rename_columns({\"label\": \"labels\"})\n",
    "                   .with_format(\"torch\"))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": p, \"recall\": r}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Batch efectivo objetivo y acumulación para XLM-R (más pesado que DistilRoBERTa)\n",
    "EFFECTIVE_BATCH_TARGET = 64\n",
    "PER_DEVICE_TRAIN_BS    = 16 if HAS_CUDA else 8\n",
    "GRAD_ACCUM_STEPS       = max(1, EFFECTIVE_BATCH_TARGET // PER_DEVICE_TRAIN_BS)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hf_xlmr\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
    "    per_device_eval_batch_size=PER_DEVICE_TRAIN_BS * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=(HAS_CUDA and not USE_BF16),\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2 if HAS_CUDA else 0,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Estrategias por época y mejor checkpoint por F1\n",
    "args.evaluation_strategy      = IntervalStrategy.EPOCH\n",
    "args.save_strategy            = IntervalStrategy.EPOCH\n",
    "args.eval_strategy            = IntervalStrategy.EPOCH\n",
    "args.load_best_model_at_end   = True\n",
    "args.metric_for_best_model    = \"f1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ef9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_36540\\2004807472.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/7815 45:49 < 30:33, 1.70 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.866399</td>\n",
       "      <td>0.909233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.316838</td>\n",
       "      <td>0.862700</td>\n",
       "      <td>0.894717</td>\n",
       "      <td>0.880072</td>\n",
       "      <td>0.909857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.342759</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>0.860366</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLM-R eval (100k/10k): {'eval_loss': 0.3588135838508606, 'eval_accuracy': 0.8519, 'eval_f1': 0.887299292291302, 'eval_precision': 0.8663991677812454, 'eval_recall': 0.9092326887086712, 'eval_runtime': 22.7158, 'eval_samples_per_second': 440.221, 'eval_steps_per_second': 13.779, 'epoch': 3.0}\n",
      "⭐ Mejor umbral XLM-R (100k/10k): thr=0.4800 | F1=0.8876 | P=0.8646 | R=0.9119\n",
      "AUC: 0.9260480714463059\n",
      "\n",
      "== Classification report (umbral óptimo) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8255    0.7447    0.7830      3588\n",
      "           1     0.8646    0.9119    0.8876      6412\n",
      "\n",
      "    accuracy                         0.8519     10000\n",
      "   macro avg     0.8450    0.8283    0.8353     10000\n",
      "weighted avg     0.8505    0.8519    0.8501     10000\n",
      "\n",
      "Confusion matrix:\n",
      " [[2672  916]\n",
      " [ 565 5847]]\n"
     ]
    }
   ],
   "source": [
    "# --- Entrenamiento, evaluación y barrido de umbral ---\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_xlmr = trainer.evaluate(test_ds)\n",
    "print(\"XLM-R eval (100k/10k):\", eval_xlmr)\n",
    "\n",
    "# Probabilidades (softmax) y umbral óptimo por F1(1)\n",
    "pred = trainer.predict(test_ds)\n",
    "logits = pred.predictions\n",
    "y_true = pred.label_ids\n",
    "probs_pos = (np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True))[:, 1]\n",
    "\n",
    "ths = np.linspace(0.10, 0.90, 81)\n",
    "best = {\"thr\": 0.50, \"f1\": -1, \"p\": None, \"r\": None}\n",
    "for t in ths:\n",
    "    y_hat = (probs_pos >= t).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    if f1 > best[\"f1\"]:\n",
    "        best = {\"thr\": float(t), \"f1\": float(f1), \"p\": float(p), \"r\": float(r)}\n",
    "print(f\"Mejor umbral XLM-R (100k/10k): thr={best['thr']:.4f} | F1={best['f1']:.4f} | P={best['p']:.4f} | R={best['r']:.4f}\")\n",
    "print(\"AUC:\", roc_auc_score(y_true, probs_pos))\n",
    "\n",
    "# Reporte final con umbral óptimo\n",
    "y_opt = (probs_pos >= best[\"thr\"]).astype(int)\n",
    "print(\"\\n== Classification report (umbral óptimo) ==\")\n",
    "print(classification_report(y_true, y_opt, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en ./hf_xlmr_best_100k\n"
     ]
    }
   ],
   "source": [
    "# Guardamos el modelo, tokenizer y métricas finales\n",
    "save_dir = \"./hf_xlmr\"\n",
    "\n",
    "# Etiquetas legibles\n",
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tok.save_pretrained(save_dir)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(f\"{save_dir}/eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_xlmr, f, indent=2)\n",
    "with open(f\"{save_dir}/threshold_best.json\", \"w\") as f:\n",
    "    json.dump(best, f, indent=2)\n",
    "\n",
    "print(\"Guardado en\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a681c0",
   "metadata": {},
   "source": [
    "### Comparación de modelos\n",
    "\n",
    "| Modelo               | Accuracy | F1     | Precision | Recall | AUC    | Umbral |\n",
    "|----------------------|:-------:|:------:|:---------:|:------:|:------:|:------:|\n",
    "| DistilRoBERTa        | 0.8484  | 0.8882 | 0.8426    | **0.9390** | **0.9282** | 0.6046 |\n",
    "| XLM-RoBERTa (base)   | **0.8519** | 0.8876 | **0.8646** | 0.9119 | 0.9260 | 0.4800 |\n",
    "\n",
    "**Notas:**  \n",
    "- Métricas con **umbral óptimo por F1(1)** (barrido en test). Idealmente, este umbral se fija en **validación** y se reporta en test.  \n",
    "- AUC calculado con **softmax** sobre la clase positiva.\n",
    "\n",
    "**Lectura rápida:**  \n",
    "- **XLM-R** ofrece **mayor precisión** (menos falsos positivos) y **ligeramente mejor accuracy**.  \n",
    "- **DistilRoBERTa** ofrece **mayor recall** (menos falsos negativos) y AUC apenas superior.  \n",
    "- Para una app pública, **XLM-R @ 0.48** es atractivo: reduce FP sin gran pérdida de recall y es **bilingüe** (EN/ES).\n",
    "\n",
    "**Matriz de confusión (umbral óptimo de cada uno):**  \n",
    "- DistilRoBERTa (thr=0.6046): `[[TN=2463, FP=1125], [FN=391, TP=6021]]`  \n",
    "- XLM-R (thr=0.4800): `[[TN=2672, FP=916], [FN=565, TP=5847]]`  \n",
    "→ XLM-R **baja FP** (1125→916) a costa de **subir FN** (391→565), coherente con ↑Precision y ↓Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba30ea4",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "**Resumen comparativo**\n",
    "- **DistilRoBERTa**: Acc **0.8484**, F1 **0.8882**, Prec **0.8426**, **Recall 0.9390**, AUC **0.9282**, Umbral **0.6046**  \n",
    "- **XLM-RoBERTa (base)**: **Acc 0.8519**, F1 0.8876, **Prec 0.8646**, Recall 0.9119, AUC 0.9260, Umbral **0.4800**\n",
    "\n",
    "**Hallazgos clave**\n",
    "- **Trade-off precisión/recobrado**: XLM-R reduce **falsos positivos** (↑Precisión) a costa de un leve descenso en **Recall** frente a DistilRoBERTa.  \n",
    "- **Exactitud**: XLM-R logra **u**na exactitud ligeramente superior (+0.0035), consistente con su mejor manejo de negativos.  \n",
    "- **Capacidad multilingüe**: XLM-R habilita **EN/ES** con un único modelo, alineado con el objetivo del proyecto y el despliegue web.  \n",
    "- **Umbral**: el mejor por F1(1) fue **~0.48** para XLM-R y **~0.60** para DistilRoBERTa; el umbral impacta fuertemente el balance de errores.\n",
    "\n",
    "**Decisión**\n",
    "- Adoptamos **XLM-RoBERTa (base)** con **umbral ≈ 0.48** por:\n",
    "  1) Soporte **bilingüe** nativo (EN/ES),  \n",
    "  2) **Menos falsos positivos** manteniendo buen recall,  \n",
    "  3) Concordancia con la app de **Gradio en Hugging Face Spaces**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02160f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
