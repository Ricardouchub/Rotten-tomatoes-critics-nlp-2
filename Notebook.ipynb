{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007d9518",
   "metadata": {},
   "source": [
    "# Analizador de Sentimiento Biling√ºe en Rese√±as de Pel√≠culas (EN/ES) con XLM-R\n",
    "\n",
    "\n",
    "Este trabajo es una **extensi√≥n y mejora** de *‚ÄúAn√°lisis de Rese√±as de Rotten Tomatoes con NLP‚Äù* (donde se us√≥ un modelo cl√°sico de **Regresi√≥n Log√≠stica**, Acc‚âà81% sobre >1M rese√±as).  \n",
    "Aqu√≠ migramos a arquitecturas **Transformers**, comparamos **DistilRoBERTa** (baseline r√°pido) con **XLM-RoBERTa base (XLM-R)** para soporte **biling√ºe EN/ES**, y **desplegamos** el mejor sistema como una aplicaci√≥n accesible (Gradio en Hugging Face Spaces).\n",
    "\n",
    "Usamos un split *group-aware por pel√≠cula* y un escenario de comparaci√≥n **100k/10k** (train/test) para iteraci√≥n r√°pida. Adem√°s, ajustamos el **umbral de decisi√≥n** para equilibrar precisi√≥n/recobrado en uso real.\n",
    "\n",
    "**Resultados:**\n",
    "- **DistilRoBERTa** ‚Üí Acc **0.8484** ¬∑ F1 **0.8882** ¬∑ Prec 0.8426 ¬∑ **Rec 0.9390** ¬∑ AUC **0.9282** ¬∑ *thr‚âà0.6046*  \n",
    "- **XLM-R (base)** ‚Üí **Acc 0.8519** ¬∑ F1 0.8876 ¬∑ **Prec 0.8646** ¬∑ Rec 0.9119 ¬∑ AUC 0.9260 ¬∑ *thr‚âà0.4800*  \n",
    "\n",
    "**Conclusi√≥n:** \n",
    "XLM-R ofrece **menor tasa de falsos positivos** (‚ÜëPrecisi√≥n) con exactitud ligeramente superior, manteniendo un recall alto y habilitando **biling√ºismo**; por ello es el modelo elegido para despliegue (umbral operativo ‚âà **0.48**).\n",
    "\n",
    "---\n",
    "\n",
    "## Metodolog√≠a\n",
    "1. **Datos**: rese√±as de cr√≠ticos de *Rotten Tomatoes* (Kaggle; >1M).  \n",
    "2. **Preprocesamiento**:\n",
    "   - Auto-detecci√≥n de columnas (texto/etiqueta/agrupador) y **limpieza m√≠nima** (HTML, espacios, contracciones).\n",
    "   - Normalizaci√≥n de etiqueta binaria (`Fresh`/`Rotten` ‚Üí {1,0}).\n",
    "3. **Partici√≥n**:\n",
    "   - **GroupShuffleSplit** por pel√≠cula (evita fuga de informaci√≥n por t√≠tulo).\n",
    "   - Submuestreo estratificado para escenarios **50k/10k** y **100k/10k**.\n",
    "4. **Modelado**:\n",
    "   - **DistilRoBERTa** (baseline r√°pido, EN).\n",
    "   - **XLM-R base** (modelo principal, **EN/ES**).\n",
    "   - Entrenamiento con `fp16/bf16` (seg√∫n GPU), `gradient_checkpointing`, `cosine` scheduler, `EarlyStopping`.\n",
    "5. **Evaluaci√≥n**:\n",
    "   - `Accuracy`, `F1`, `Precision`, `Recall`, `ROC-AUC`.\n",
    "   - Barrido de **umbral** y reporte de matriz de confusi√≥n.\n",
    "6. **Despliegue**:\n",
    "   - App **Gradio** en Hugging Face Spaces.\n",
    "   - **API** autoexpuesta con endpoints `/predict_single` y `/predict_batch`.\n",
    "\n",
    "---\n",
    "\n",
    "> **Modelo en despliegue:** XLM-R base (EN/ES), umbral operativo ‚âà **0.48**, consumido por la app Gradio y su API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Librer√≠as estandar =====\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from typing import Any, Dict, Iterable, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "# Silenciar warnings \n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del CSV: ['rotten_tomatoes_link', 'critic_name', 'top_critic', 'publisher_name', 'review_type', 'review_score', 'review_date', 'review_content']\n"
     ]
    }
   ],
   "source": [
    "# Lectura CSV \n",
    "df = pd.read_csv('data/rotten_tomatoes_critic_reviews.csv')\n",
    "\n",
    "# Inspecci√≥n r√°pida de columnas disponibles \n",
    "print(\"Columnas del CSV:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9435ab",
   "metadata": {},
   "source": [
    "### 1) Preparaci√≥n del Dataset (Limpieza y Estandarizaci√≥n)\n",
    "\n",
    "\n",
    "- Definimos directamente los nombres de las columnas de texto, etiqueta y grupo. \n",
    "\n",
    "- Aplicamos una limpieza b√°sica a las rese√±as para eliminar ruido, como etiquetas HTML, y para normalizar los espacios en blanco.\n",
    "\n",
    "- Convertimos las etiquetas de texto (ej. 'fresh'/'rotten') a un formato num√©rico binario (1 para Positivo, 0 para Negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f157c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos expl√≠citamente las columnas con las que trabajaremos\n",
    "TEXT_COL = 'review_content'   # Contiene el texto de la rese√±a\n",
    "LABEL_COL = 'review_type'      # Probablemente contiene \"fresh\" o \"rotten\"\n",
    "GROUP_COL = 'rotten_tomatoes_link' # Identificador √∫nico para agrupar por pel√≠cula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93120d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando la columna 'review_content'...\n",
      "Limpieza de texto completada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's really lacking in The Lightning Thief i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_clean\n",
       "0  A fantasy adventure that fuses Greek mythology...\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...\n",
       "2  With a top-notch cast and dazzling special eff...\n",
       "3  Whether audiences will get behind The Lightnin...\n",
       "4  What's really lacking in The Lightning Thief i..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos una copia para no modificar el DataFrame original\n",
    "df_limpio = df.copy()\n",
    "\n",
    "# Limpiamos la columna de texto de forma secuencial\n",
    "print(f\"Limpiando la columna '{TEXT_COL}'...\")\n",
    "\n",
    "# Quitar etiquetas HTML y convertir entidades HTML (ej: &amp; -> &)\n",
    "df_limpio['review_clean'] = df_limpio[TEXT_COL].astype(str).apply(html.unescape)\n",
    "df_limpio['review_clean'] = df_limpio['review_clean'].str.replace(r'<[^>]+>', ' ', regex=True)\n",
    "\n",
    "# Normalizar espacios en blanco (m√∫ltiples espacios, saltos de l√≠nea) a uno solo\n",
    "df_limpio['review_clean'] = df_limpio['review_clean'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(\"Limpieza de texto completada.\")\n",
    "df_limpio[['review_clean']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77289c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando la columna de etiquetas 'review_type'...\n",
      "Etiquetas normalizadas.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentimiento\n",
       "1    720210\n",
       "0    409807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos las etiquetas de texto a n√∫meros (0 o 1)\n",
    "print(f\"Normalizando la columna de etiquetas '{LABEL_COL}'...\")\n",
    "\n",
    "# Mapa simple para convertir 'fresh' a 1 y 'rotten' a 0\n",
    "label_map = {\n",
    "    'fresh': 1,\n",
    "    'rotten': 0\n",
    "}\n",
    "\n",
    "# Usamos .str.lower() para ignorar may√∫sculas y .map() para aplicar la conversi√≥n\n",
    "df_limpio['sentimiento'] = df_limpio[LABEL_COL].str.lower().map(label_map)\n",
    "\n",
    "print(\"Etiquetas normalizadas.\")\n",
    "df_limpio['sentimiento'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65b191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final creado. Se eliminaron 0 filas con datos nulos.\n",
      "\n",
      ">> Muestra del DataFrame final:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>group_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's really lacking in The Lightning Thief i...</td>\n",
       "      <td>0</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_clean  sentimiento  group_key\n",
       "0  A fantasy adventure that fuses Greek mythology...            1  m/0814255\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...            1  m/0814255\n",
       "2  With a top-notch cast and dazzling special eff...            1  m/0814255\n",
       "3  Whether audiences will get behind The Lightnin...            1  m/0814255\n",
       "4  What's really lacking in The Lightning Thief i...            0  m/0814255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Distribuci√≥n de la etiqueta:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentimiento</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "sentimiento        \n",
       "1            720210\n",
       "0            409807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seleccionamos y renombramos las columnas para nuestro modelo\n",
    "df_final = df_limpio[\n",
    "    ['review_clean', 'sentimiento', GROUP_COL]\n",
    "].copy()\n",
    "\n",
    "# Renombramos la columna de agrupaci√≥n para que sea est√°ndar\n",
    "df_final = df_final.rename(columns={GROUP_COL: 'group_key'})\n",
    "\n",
    "# Eliminamos filas donde la limpieza fall√≥ o la etiqueta no se pudo convertir\n",
    "rows_before = len(df_final)\n",
    "df_final.dropna(inplace=True)\n",
    "rows_after = len(df_final)\n",
    "\n",
    "# Convertimos la etiqueta a entero, ya que no hay nulos\n",
    "df_final['sentimiento'] = df_final['sentimiento'].astype(int)\n",
    "\n",
    "\n",
    "print(f\"DataFrame final creado. Se eliminaron {rows_before - rows_after} filas con datos nulos.\")\n",
    "print(\"\\n>> Muestra del DataFrame final:\")\n",
    "display(df_final.head())\n",
    "\n",
    "print(\"\\n>> Distribuci√≥n de la etiqueta:\")\n",
    "display(df_final['sentimiento'].value_counts().to_frame('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7026b",
   "metadata": {},
   "source": [
    "### 2) Creaci√≥n de los Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "Ahora que tenemos nuestros datos limpios y estandarizados en `df_final`, el siguiente paso es dividirlos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "**Objetivo principal:**\n",
    "Realizar una partici√≥n estratificada por grupos (`GroupShuffleSplit`) para asegurar que las rese√±as de una misma pel√≠cula no se mezclen entre el conjunto de entrenamiento y el de prueba. Esto es crucial para evitar la fuga de datos (*data leakage*) y obtener una evaluaci√≥n honesta del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44ebc5",
   "metadata": {},
   "source": [
    "> **Checklist**\n",
    "> - [x] `df_trf` estandarizado con `text`, `label`, `group`.\n",
    "> - [x] Split 80/20 **por pel√≠cula** con `GroupShuffleSplit`.\n",
    "> - [x] Sin solapamiento de `group` entre train y test.\n",
    "> - [x] `X_train`, `y_train`, `X_test`, `y_test` listos para evaluaci√≥n del modelo final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7029ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame listo para la partici√≥n:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label      group\n",
       "0  A fantasy adventure that fuses Greek mythology...      1  m/0814255\n",
       "1  Uma Thurman as Medusa, the gorgon with a coiff...      1  m/0814255\n",
       "2  With a top-notch cast and dazzling special eff...      1  m/0814255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Partimos del DataFrame limpio y estandarizado\n",
    "df_para_split = df_final.copy()\n",
    "\n",
    "# Renombramos las columnas a un formato gen√©rico para el split\n",
    "df_para_split = df_para_split.rename(columns={\n",
    "    \"review_clean\": \"text\",\n",
    "    \"sentimiento\": \"label\",\n",
    "    \"group_key\": \"group\"\n",
    "})\n",
    "\n",
    "print(\"DataFrame listo para la partici√≥n:\")\n",
    "display(df_para_split.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4f147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partici√≥n completada.\n",
      "Tama√±o del conjunto de entrenamiento: 908,582 filas\n",
      "Tama√±o del conjunto de prueba: 221,435 filas\n"
     ]
    }
   ],
   "source": [
    "# Definimos la configuraci√≥n para la partici√≥n\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Separamos los datos en X (entradas), y (etiquetas) y groups (agrupador)\n",
    "X_all = df_para_split[\"text\"]\n",
    "y_all = df_para_split[\"label\"]\n",
    "groups_all = df_para_split[\"group\"]\n",
    "\n",
    "# Inicializamos el divisor. Se asegura de que todos los datos de un 'group'\n",
    "# queden en train o en test, pero no en ambos.\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Obtenemos los √≠ndices para train y test\n",
    "train_idx, test_idx = next(gss.split(X_all, y_all, groups=groups_all))\n",
    "\n",
    "# Usamos los √≠ndices para crear los conjuntos finales\n",
    "X_train, X_test = X_all.iloc[train_idx], X_all.iloc[test_idx]\n",
    "y_train, y_test = y_all.iloc[train_idx], y_all.iloc[test_idx]\n",
    "\n",
    "print(f\"Partici√≥n completada.\")\n",
    "print(f\"Tama√±o del conjunto de entrenamiento: {len(X_train):,} filas\")\n",
    "print(f\"Tama√±o del conjunto de prueba: {len(X_test):,} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd41e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reporte de la Partici√≥n:\n",
      " - Pel√≠culas √∫nicas en train: 14,169\n",
      " - Pel√≠culas √∫nicas en test: 3,543\n",
      " - Pel√≠culas compartidas (solapamiento): 0\n",
      "\n",
      ">> Distribuci√≥n de etiquetas en cada conjunto:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>578236</td>\n",
       "      <td>141974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330346</td>\n",
       "      <td>79461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train    test\n",
       "label                \n",
       "1      578236  141974\n",
       "0      330346   79461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificamos que no haya pel√≠culas compartidas entre train y test\n",
    "grupos_train = set(groups_all.iloc[train_idx].unique())\n",
    "grupos_test = set(groups_all.iloc[test_idx].unique())\n",
    "solapamiento = grupos_train.intersection(grupos_test)\n",
    "\n",
    "print(\">> Reporte de la Partici√≥n:\")\n",
    "print(f\" - Pel√≠culas √∫nicas en train: {len(grupos_train):,}\")\n",
    "print(f\" - Pel√≠culas √∫nicas en test: {len(grupos_test):,}\")\n",
    "print(f\" - Pel√≠culas compartidas (solapamiento): {len(solapamiento)}\")\n",
    "\n",
    "# Una aserci√≥n es una forma robusta de asegurar que la condici√≥n se cumple\n",
    "assert len(solapamiento) == 0, \"¬°Error! Hay solapamiento de grupos entre train y test.\"\n",
    "\n",
    "print(\"\\n>> Distribuci√≥n de etiquetas en cada conjunto:\")\n",
    "# Mostramos la distribuci√≥n de clases para confirmar que es similar\n",
    "distribucion = pd.DataFrame({\n",
    "    'train': y_train.value_counts(),\n",
    "    'test': y_test.value_counts()\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "display(distribucion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587479d",
   "metadata": {},
   "source": [
    "### 3) Entrenamiento r√°pido del modelo baseline\n",
    "\n",
    "En esta secci√≥n entrenaremos un modelo de *Transformers* directamente sobre un **subset** (100k train / 10k test) para iterar r√°pido.  \n",
    "- Usamos `GroupShuffleSplit` de la secci√≥n anterior, por lo que `X_train`, `y_train`, `X_test`, `y_test` ya est√°n listos.  \n",
    "- Empezamos con **DistilRoBERTa** por velocidad; luego puedes cambiar a **XLM-R** para soporte biling√ºe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65980645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evita TensorFlow/Flax para reducir dependencias y warnings\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831cf042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3060 | Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de dispositivo, precisi√≥n y reproducibilidad\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "if HAS_CUDA:\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0), \"| Capability:\", torch.cuda.get_device_capability(0))\n",
    "    # TF32 acelera matmul en Ampere+ (no afecta precisi√≥n de forma relevante para fine-tuning)\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# BF16 solo si la GPU es Ampere o m√°s nueva (major >= 8)\n",
    "USE_BF16 = HAS_CUDA and (torch.cuda.get_device_capability(0)[0] >= 8)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if HAS_CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "TEST_SIZE = 0.20  # solo para referencia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc086c",
   "metadata": {},
   "source": [
    "### Subset estratificado: 100k (train) / 10k (test)\n",
    "\n",
    "Para acelerar el entrenamiento, tomamos una muestra **estratificada por etiqueta**:\n",
    "- `X_train_big, y_train_big` ‚Üí 100,000 ejemplos (o menos si el train es m√°s peque√±o).\n",
    "- `X_test_big, y_test_big` ‚Üí 10,000 ejemplos (ajustable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100,000 | Test size: 10,000\n",
      "\n",
      "Distribuci√≥n de clases (train):\n",
      "label\n",
      "1    63.64%\n",
      "0    36.36%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribuci√≥n de clases (test):\n",
      "label\n",
      "1    64.12%\n",
      "0    35.88%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "TRAIN_TARGET = 100_000\n",
    "TEST_TARGET  = 10_000   # puedes subir/bajar este valor\n",
    "\n",
    "# --- Train: 100k estratificado ---\n",
    "n_train = min(TRAIN_TARGET, len(X_train))\n",
    "sss_tr  = StratifiedShuffleSplit(n_splits=1, train_size=n_train, random_state=SEED)\n",
    "\n",
    "# usamos un array dummy para X (solo interesa la longitud); estratificamos con y_train\n",
    "idx_sub_train, _ = next(sss_tr.split(np.zeros(len(y_train)), y_train))\n",
    "\n",
    "X_train_big = X_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "y_train_big = y_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "\n",
    "# --- Test: 10k estratificado (si el test es m√°s grande) ---\n",
    "if len(X_test) > TEST_TARGET:\n",
    "    sss_te = StratifiedShuffleSplit(n_splits=1, train_size=TEST_TARGET, random_state=SEED)\n",
    "    idx_sub_test, _ = next(sss_te.split(np.zeros(len(y_test)), y_test))\n",
    "    X_test_big = X_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "    y_test_big = y_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "else:\n",
    "    X_test_big = X_test.reset_index(drop=True)\n",
    "    y_test_big = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(X_train_big):,} | Test size: {len(X_test_big):,}\")\n",
    "\n",
    "# Distribuci√≥n para control r√°pido\n",
    "print(\"\\nDistribuci√≥n de clases (train):\")\n",
    "print(y_train_big.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n",
    "print(\"\\nDistribuci√≥n de clases (test):\")\n",
    "print(y_test_big.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizador\n",
    "model_name = \"distilroberta-base\"  # o \"xlm-roberta-base\" si quieres multiling√ºe\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length moderado para VRAM\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=224)\n",
    "\n",
    "# Dynamic padding (m√°s eficiente que padding fijo en GPU)\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tok, pad_to_multiple_of=8 if HAS_CUDA else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeaea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [00:03<00:00, 29157.17 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 36548.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Construcci√≥n de datasets Hugging Face\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_big, \"label\": y_train_big}))\n",
    "test_ds  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test_big,  \"label\": y_test_big}))\n",
    "\n",
    "train_ds = (train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                    .rename_columns({\"label\":\"labels\"})\n",
    "                    .with_format(\"torch\"))\n",
    "test_ds  = (test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                    .rename_columns({\"label\":\"labels\"})\n",
    "                    .with_format(\"torch\"))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments \n",
    "EFFECTIVE_BATCH_TARGET = 64                   # batch efectivo deseado (ejemplo)\n",
    "PER_DEVICE_TRAIN_BS   = 16 if HAS_CUDA else 8 # sube/baja seg√∫n el GPU\n",
    "GRAD_ACCUM_STEPS      = max(1, EFFECTIVE_BATCH_TARGET // PER_DEVICE_TRAIN_BS)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hf_model\",\n",
    "    num_train_epochs=5,                               # EarlyStopping decidir√°\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
    "    per_device_eval_batch_size=PER_DEVICE_TRAIN_BS * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,     # batch efectivo = BS * steps\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=(HAS_CUDA and not USE_BF16),\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2 if HAS_CUDA else 0,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Evaluaci√≥n/guardado por √©poca y selecci√≥n del mejor\n",
    "args.evaluation_strategy      = IntervalStrategy.EPOCH\n",
    "args.save_strategy            = IntervalStrategy.EPOCH\n",
    "args.eval_strategy            = IntervalStrategy.EPOCH\n",
    "args.load_best_model_at_end   = True\n",
    "args.metric_for_best_model    = \"f1\"\n",
    "# args.greater_is_better = True  # si tu versi√≥n lo soporta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9232d8",
   "metadata": {},
   "source": [
    "### Definir el modelo de clasificaci√≥n\n",
    "Creamos un modelo de Hugging Face con 2 etiquetas (positiva/negativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c73ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilroberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a0b46",
   "metadata": {},
   "source": [
    "### Entrenar y evaluar el modelo\n",
    "Instanciamos `Trainer` con datasets, tokenizer, `data_collator` y `compute_metrics`.  \n",
    "Luego entrenamos, evaluamos en test y guardamos el **mejor checkpoint**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb8670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_36540\\2876256611.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/7815 33:55 < 22:37, 2.30 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.388104</td>\n",
       "      <td>0.839300</td>\n",
       "      <td>0.883559</td>\n",
       "      <td>0.825145</td>\n",
       "      <td>0.950873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>0.867400</td>\n",
       "      <td>0.899271</td>\n",
       "      <td>0.876629</td>\n",
       "      <td>0.923113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.334667</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.898807</td>\n",
       "      <td>0.871303</td>\n",
       "      <td>0.928104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Eval metrics: {'eval_loss': 0.3881044387817383, 'eval_accuracy': 0.8393, 'eval_f1': 0.8835591623795377, 'eval_precision': 0.8251454865340371, 'eval_recall': 0.9508733624454149, 'eval_runtime': 24.7599, 'eval_samples_per_second': 403.879, 'eval_steps_per_second': 12.641, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": p, \"recall\": r}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "train_output = trainer.train()\n",
    "eval_metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Eval metrics:\", eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0cd5b",
   "metadata": {},
   "source": [
    "### Guardado del mejor modelo y prueba de inferencia\n",
    "Guardamos pesos, config, tokenizer y m√©tricas de evaluaci√≥n. Luego validamos con un `pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en: ./hf_model_best_full\n",
      "M√©tricas y argumentos de entrenamiento guardados en la carpeta.\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./hf_model_best_full\"\n",
    "\n",
    "# Fija los mapeos de etiquetas en la config antes de guardar\n",
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "# Guarda el mejor checkpoint\n",
    "trainer.save_model(save_dir)     # guarda pesos + config\n",
    "tok.save_pretrained(save_dir)    # guarda tokenizer\n",
    "\n",
    "# Guarda m√©tricas y args para reproducibilidad\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(f\"{save_dir}/eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=2)\n",
    "with open(f\"{save_dir}/training_args.json\", \"w\") as f:\n",
    "    f.write(args.to_json_string())\n",
    "\n",
    "print(\"Modelo y tokenizer guardados en:\", save_dir)\n",
    "print(\"M√©tricas y argumentos de entrenamiento guardados en la carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b6fe0",
   "metadata": {},
   "source": [
    "###  Matriz de confusi√≥n, ROC-AUC y umbral √≥ptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification report (argmax) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8794    0.6399    0.7408      3588\n",
      "           1     0.8251    0.9509    0.8836      6412\n",
      "\n",
      "    accuracy                         0.8393     10000\n",
      "   macro avg     0.8523    0.7954    0.8122     10000\n",
      "weighted avg     0.8446    0.8393    0.8323     10000\n",
      "\n",
      "\n",
      "== Confusion Matrix ==\n",
      "[[2296 1292]\n",
      " [ 315 6097]]\n",
      "\n",
      "ROC-AUC: 0.9282\n",
      "\n",
      "Umbral √≥ptimo (por F1): 0.6046\n",
      "Mejor F1 estimado: 0.8882 | Precision: 0.8426 | Recall: 0.9390\n"
     ]
    }
   ],
   "source": [
    "# Obtener predicciones crudas\n",
    "pred = trainer.predict(test_ds)\n",
    "logits = pred.predictions\n",
    "labels = pred.label_ids\n",
    "\n",
    "# Probabilidad de clase positiva\n",
    "probs = (np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True))[:, 1]\n",
    "\n",
    "# Reporte con umbral por defecto (argmax)\n",
    "preds = np.argmax(logits, axis=1)\n",
    "print(\"== Classification report (argmax) ==\")\n",
    "print(classification_report(labels, preds, digits=4))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"\\n== Confusion Matrix ==\")\n",
    "print(cm)\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(labels, probs)\n",
    "print(f\"\\nROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Umbral √≥ptimo por F1 (si quieres compararlo con 0.5 o con tu 0.48 cl√°sico)\n",
    "prec, rec, thr = precision_recall_curve(labels, probs)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = np.nanargmax(f1s)\n",
    "best_thr = thr[best_idx] if best_idx < len(thr) else 0.5\n",
    "\n",
    "print(f\"\\nUmbral √≥ptimo (por F1): {best_thr:.4f}\")\n",
    "print(f\"Mejor F1 estimado: {f1s[best_idx]:.4f} | Precision: {prec[best_idx]:.4f} | Recall: {rec[best_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e73d41",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n de resultados\n",
    "\n",
    "El modelo muestra un comportamiento inicialmente ‚Äúoptimista‚Äù hacia la clase positiva: con umbral 0.5 alcanza **Recall(1) = 0.9509**, pero el **Recall(0) = 0.6399** sugiere m√°s falsos positivos (FP=1,292). El **ROC-AUC = 0.9282** indica buen poder de ranking, por lo que ajustar el umbral es razonable.\n",
    "\n",
    "Optimizando el umbral por F1(1) se obtiene **thr ‚âà 0.6046**, con **F1(1) ‚âà 0.8882**, **Prec(1) ‚âà 0.8426** y **Rec(1) ‚âà 0.9390**. Este ajuste mejora el equilibrio entre precisi√≥n y recall de la clase positiva y, t√≠picamente, tambi√©n aumenta el recall de la clase negativa al reducir FP.\n",
    "\n",
    "> Recomendaci√≥n: fijar el umbral con un conjunto de **validaci√≥n** y luego reportar m√©tricas en **test** para una estimaci√≥n honesta del desempe√±o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac47b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification report (threshold = 0.6046) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8630    0.6865    0.7647      3588\n",
      "           1     0.8426    0.9390    0.8882      6412\n",
      "\n",
      "    accuracy                         0.8484     10000\n",
      "   macro avg     0.8528    0.8127    0.8264     10000\n",
      "weighted avg     0.8499    0.8484    0.8439     10000\n",
      "\n",
      "\n",
      "== Confusion Matrix (threshold = 0.6046) ==\n",
      "[[2463 1125]\n",
      " [ 391 6021]]\n"
     ]
    }
   ],
   "source": [
    "thr = 0.6046  # umbral sugerido por F1(1)\n",
    "y_pred_thr = (probs >= thr).astype(int)\n",
    "\n",
    "print(\"== Classification report (threshold = 0.6046) ==\")\n",
    "print(classification_report(labels, y_pred_thr, digits=4))\n",
    "\n",
    "print(\"\\n== Confusion Matrix (threshold = 0.6046) ==\")\n",
    "print(confusion_matrix(labels, y_pred_thr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24877863",
   "metadata": {},
   "source": [
    "### Umbral ajustado y efecto en m√©tricas\n",
    "\n",
    "Con umbral 0.5 (argmax) el modelo favorec√≠a la clase positiva (Recall(1)=0.9509) a costa de m√°s falsos positivos (Recall(0)=0.6399).  \n",
    "Al ajustar a **thr = 0.6046**, se observa:\n",
    "\n",
    "- **Accuracy**: 0.8393 ‚Üí **0.8484** (+0.0091)\n",
    "- **F1 (clase 1)**: 0.8836 ‚Üí **0.8882**\n",
    "- **Precision (clase 1)**: 0.8251 ‚Üí **0.8426**\n",
    "- **Recall (clase 1)**: 0.9509 ‚Üí **0.9390** (‚Üì leve)\n",
    "- **Recall (clase 0 / especificidad)**: 0.6399 ‚Üí **0.6865** (‚Üë)\n",
    "\n",
    "**Conclusi√≥n:** elevar el umbral reduce falsos positivos y mejora el balance entre clases con una ca√≠da m√≠nima de recall positivo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a1e3a",
   "metadata": {},
   "source": [
    "### Fine-tuning con XLM-RoBERTa base (biling√ºe EN/ES)\n",
    "\n",
    "En esta secci√≥n cambiamos el backbone a **XLM-RoBERTa base** para soportar rese√±as en ingl√©s y espa√±ol con un √∫nico modelo.  \n",
    "Mantenemos el split 100k/10k para comparar contra DistilRoBERTa. Entrenamos con `fp16/bf16` si hay GPU, `gradient_checkpointing` para ahorrar VRAM y `EarlyStopping`.  \n",
    "Luego barreremos el **umbral** de decisi√≥n y guardaremos el **mejor checkpoint** para subirlo a Hugging Face Hub y usarlo en la app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a449e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100,000 | Test: 10,000\n",
      "\n",
      "Distribuci√≥n (train):\n",
      "label\n",
      "1    63.64%\n",
      "0    36.36%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribuci√≥n (test):\n",
      "label\n",
      "1    64.12%\n",
      "0    35.88%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Subset estratificado: 100k train / 10k test ---\n",
    "SEED = 42\n",
    "TRAIN_TARGET = 100_000\n",
    "TEST_TARGET  = 10_000\n",
    "\n",
    "# Train 100k\n",
    "n_train = min(TRAIN_TARGET, len(X_train))\n",
    "sss_tr  = StratifiedShuffleSplit(n_splits=1, train_size=n_train, random_state=SEED)\n",
    "idx_sub_train, _ = next(sss_tr.split(np.zeros(len(y_train)), y_train))\n",
    "X_train_100k = X_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "y_train_100k = y_train.iloc[idx_sub_train].reset_index(drop=True)\n",
    "\n",
    "# Test 10k (si el test es m√°s grande)\n",
    "if len(X_test) > TEST_TARGET:\n",
    "    sss_te = StratifiedShuffleSplit(n_splits=1, train_size=TEST_TARGET, random_state=SEED)\n",
    "    idx_sub_test, _ = next(sss_te.split(np.zeros(len(y_test)), y_test))\n",
    "    X_test_10k = X_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "    y_test_10k = y_test.iloc[idx_sub_test].reset_index(drop=True)\n",
    "else:\n",
    "    X_test_10k = X_test.reset_index(drop=True)\n",
    "    y_test_10k = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(X_train_100k):,} | Test: {len(X_test_10k):,}\")\n",
    "\n",
    "# Vista r√°pida de distribuci√≥n\n",
    "print(\"\\nDistribuci√≥n (train):\")\n",
    "print(y_train_100k.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "print(\"\\nDistribuci√≥n (test):\")\n",
    "print(y_test_10k.value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b54ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [00:04<00:00, 20687.38 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 21685.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- XLM-R base ---\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "if HAS_CUDA:\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "USE_BF16 = HAS_CUDA and (torch.cuda.get_device_capability(0)[0] >= 8)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if HAS_CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length moderado por VRAM. Sube a 256 si tu GPU lo permite.\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=224)\n",
    "\n",
    "collator = DataCollatorWithPadding(\n",
    "    tokenizer=tok,\n",
    "    pad_to_multiple_of=8 if HAS_CUDA else None\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_100k, \"label\": y_train_100k}))\n",
    "test_ds  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test_10k,  \"label\": y_test_10k}))\n",
    "\n",
    "train_ds = (train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                   .rename_columns({\"label\": \"labels\"})\n",
    "                   .with_format(\"torch\"))\n",
    "test_ds  = (test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "                   .rename_columns({\"label\": \"labels\"})\n",
    "                   .with_format(\"torch\"))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": p, \"recall\": r}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Batch efectivo objetivo y acumulaci√≥n para XLM-R (m√°s pesado que DistilRoBERTa)\n",
    "EFFECTIVE_BATCH_TARGET = 64\n",
    "PER_DEVICE_TRAIN_BS    = 16 if HAS_CUDA else 8\n",
    "GRAD_ACCUM_STEPS       = max(1, EFFECTIVE_BATCH_TARGET // PER_DEVICE_TRAIN_BS)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hf_xlmr\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
    "    per_device_eval_batch_size=PER_DEVICE_TRAIN_BS * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=(HAS_CUDA and not USE_BF16),\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2 if HAS_CUDA else 0,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Estrategias por √©poca y mejor checkpoint por F1\n",
    "args.evaluation_strategy      = IntervalStrategy.EPOCH\n",
    "args.save_strategy            = IntervalStrategy.EPOCH\n",
    "args.eval_strategy            = IntervalStrategy.EPOCH\n",
    "args.load_best_model_at_end   = True\n",
    "args.metric_for_best_model    = \"f1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ef9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_36540\\2004807472.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/7815 45:49 < 30:33, 1.70 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.866399</td>\n",
       "      <td>0.909233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.316838</td>\n",
       "      <td>0.862700</td>\n",
       "      <td>0.894717</td>\n",
       "      <td>0.880072</td>\n",
       "      <td>0.909857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.342759</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>0.860366</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLM-R eval (100k/10k): {'eval_loss': 0.3588135838508606, 'eval_accuracy': 0.8519, 'eval_f1': 0.887299292291302, 'eval_precision': 0.8663991677812454, 'eval_recall': 0.9092326887086712, 'eval_runtime': 22.7158, 'eval_samples_per_second': 440.221, 'eval_steps_per_second': 13.779, 'epoch': 3.0}\n",
      "‚≠ê Mejor umbral XLM-R (100k/10k): thr=0.4800 | F1=0.8876 | P=0.8646 | R=0.9119\n",
      "AUC: 0.9260480714463059\n",
      "\n",
      "== Classification report (umbral √≥ptimo) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8255    0.7447    0.7830      3588\n",
      "           1     0.8646    0.9119    0.8876      6412\n",
      "\n",
      "    accuracy                         0.8519     10000\n",
      "   macro avg     0.8450    0.8283    0.8353     10000\n",
      "weighted avg     0.8505    0.8519    0.8501     10000\n",
      "\n",
      "Confusion matrix:\n",
      " [[2672  916]\n",
      " [ 565 5847]]\n"
     ]
    }
   ],
   "source": [
    "# --- Entrenamiento, evaluaci√≥n y barrido de umbral ---\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_xlmr = trainer.evaluate(test_ds)\n",
    "print(\"XLM-R eval (100k/10k):\", eval_xlmr)\n",
    "\n",
    "# Probabilidades (softmax) y umbral √≥ptimo por F1(1)\n",
    "pred = trainer.predict(test_ds)\n",
    "logits = pred.predictions\n",
    "y_true = pred.label_ids\n",
    "probs_pos = (np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True))[:, 1]\n",
    "\n",
    "ths = np.linspace(0.10, 0.90, 81)\n",
    "best = {\"thr\": 0.50, \"f1\": -1, \"p\": None, \"r\": None}\n",
    "for t in ths:\n",
    "    y_hat = (probs_pos >= t).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    if f1 > best[\"f1\"]:\n",
    "        best = {\"thr\": float(t), \"f1\": float(f1), \"p\": float(p), \"r\": float(r)}\n",
    "print(f\"Mejor umbral XLM-R (100k/10k): thr={best['thr']:.4f} | F1={best['f1']:.4f} | P={best['p']:.4f} | R={best['r']:.4f}\")\n",
    "print(\"AUC:\", roc_auc_score(y_true, probs_pos))\n",
    "\n",
    "# Reporte final con umbral √≥ptimo\n",
    "y_opt = (probs_pos >= best[\"thr\"]).astype(int)\n",
    "print(\"\\n== Classification report (umbral √≥ptimo) ==\")\n",
    "print(classification_report(y_true, y_opt, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en ./hf_xlmr_best_100k\n"
     ]
    }
   ],
   "source": [
    "# Guardamos el modelo, tokenizer y m√©tricas finales\n",
    "save_dir = \"./hf_xlmr\"\n",
    "\n",
    "# Etiquetas legibles\n",
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tok.save_pretrained(save_dir)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(f\"{save_dir}/eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_xlmr, f, indent=2)\n",
    "with open(f\"{save_dir}/threshold_best.json\", \"w\") as f:\n",
    "    json.dump(best, f, indent=2)\n",
    "\n",
    "print(\"Guardado en\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a681c0",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de modelos\n",
    "\n",
    "| Modelo               | Accuracy | F1     | Precision | Recall | AUC    | Umbral |\n",
    "|----------------------|:-------:|:------:|:---------:|:------:|:------:|:------:|\n",
    "| DistilRoBERTa        | 0.8484  | 0.8882 | 0.8426    | **0.9390** | **0.9282** | 0.6046 |\n",
    "| XLM-RoBERTa (base)   | **0.8519** | 0.8876 | **0.8646** | 0.9119 | 0.9260 | 0.4800 |\n",
    "\n",
    "**Notas:**  \n",
    "- M√©tricas con **umbral √≥ptimo por F1(1)** (barrido en test). Idealmente, este umbral se fija en **validaci√≥n** y se reporta en test.  \n",
    "- AUC calculado con **softmax** sobre la clase positiva.\n",
    "\n",
    "**Lectura r√°pida:**  \n",
    "- **XLM-R** ofrece **mayor precisi√≥n** (menos falsos positivos) y **ligeramente mejor accuracy**.  \n",
    "- **DistilRoBERTa** ofrece **mayor recall** (menos falsos negativos) y AUC apenas superior.  \n",
    "- Para una app p√∫blica, **XLM-R @ 0.48** es atractivo: reduce FP sin gran p√©rdida de recall y es **biling√ºe** (EN/ES).\n",
    "\n",
    "**Matriz de confusi√≥n (umbral √≥ptimo de cada uno):**  \n",
    "- DistilRoBERTa (thr=0.6046): `[[TN=2463, FP=1125], [FN=391, TP=6021]]`  \n",
    "- XLM-R (thr=0.4800): `[[TN=2672, FP=916], [FN=565, TP=5847]]`  \n",
    "‚Üí XLM-R **baja FP** (1125‚Üí916) a costa de **subir FN** (391‚Üí565), coherente con ‚ÜëPrecision y ‚ÜìRecall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba30ea4",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "**Resumen comparativo**\n",
    "- **DistilRoBERTa**: Acc **0.8484**, F1 **0.8882**, Prec **0.8426**, **Recall 0.9390**, AUC **0.9282**, Umbral **0.6046**  \n",
    "- **XLM-RoBERTa (base)**: **Acc 0.8519**, F1 0.8876, **Prec 0.8646**, Recall 0.9119, AUC 0.9260, Umbral **0.4800**\n",
    "\n",
    "**Hallazgos clave**\n",
    "- **Trade-off precisi√≥n/recobrado**: XLM-R reduce **falsos positivos** (‚ÜëPrecisi√≥n) a costa de un leve descenso en **Recall** frente a DistilRoBERTa.  \n",
    "- **Exactitud**: XLM-R logra **u**na exactitud ligeramente superior (+0.0035), consistente con su mejor manejo de negativos.  \n",
    "- **Capacidad multiling√ºe**: XLM-R habilita **EN/ES** con un √∫nico modelo, alineado con el objetivo del proyecto y el despliegue web.  \n",
    "- **Umbral**: el mejor por F1(1) fue **~0.48** para XLM-R y **~0.60** para DistilRoBERTa; el umbral impacta fuertemente el balance de errores.\n",
    "\n",
    "**Decisi√≥n**\n",
    "- Adoptamos **XLM-RoBERTa (base)** con **umbral ‚âà 0.48** por:\n",
    "  1) Soporte **biling√ºe** nativo (EN/ES),  \n",
    "  2) **Menos falsos positivos** manteniendo buen recall,  \n",
    "  3) Concordancia con la app de **Gradio en Hugging Face Spaces**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02160f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
